{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329f6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Path to images\n",
    "data_path = fr'../Datasets/full/Training'\n",
    "\n",
    "def remove_white_background(pixels):\n",
    "    newPixels = []\n",
    "    for pixel in pixels:\n",
    "        pixel = list(pixel)\n",
    "        if ((256 > pixel[0] > 200) and (256 > pixel[1] > 200) and (256 > pixel[2] > 200)):\n",
    "            pixel[0] = 0\n",
    "            pixel[1] = 0\n",
    "            pixel[2] = 0\n",
    "        newPixels.append(pixel)\n",
    "    \n",
    "    return newPixels\n",
    "\n",
    "def grayscale(pixels):\n",
    "    newPixels = []\n",
    "    for pixel in pixels:\n",
    "        pixel = tuple(pixel)\n",
    "        newPixels.append(pixel)\n",
    "    \n",
    "    newImg = Image.new(\"RGB\", (24,24))\n",
    "    newImg.putdata(newPixels)\n",
    "    greyImg = newImg.convert('L')\n",
    "    return list(greyImg.getdata())\n",
    "\n",
    "def get_rgb_pixels_onehot_labels(src):\n",
    "    print(\"Starting...\")\n",
    "    newPixels = []\n",
    "    y = np.empty(shape=[0, 1])\n",
    "\n",
    "    for subdir in os.listdir(src):\n",
    "        current_path = os.path.join(src, subdir)\n",
    "        for file in os.listdir(current_path):\n",
    "            img = Image.open(os.path.join(current_path, file))\n",
    "            imgResize = img.resize((24,24))\n",
    "            pixels = list(imgResize.getdata())\n",
    "            pixels = remove_white_background(pixels)\n",
    "            pixels = grayscale(pixels)\n",
    "            newPixels.append(pixels)\n",
    "            y = np.append(y, subdir)\n",
    "    return newPixels, LabelBinarizer().fit_transform(y) # OneHot encode y\n",
    "\n",
    "def process_files(src):\n",
    "    X_grey_train = []\n",
    "    X_grey_validation = []\n",
    "    X_grey_test = []\n",
    "    all_pixels, y = get_rgb_pixels_onehot_labels(src)\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(all_pixels, y, test_size=0.2, random_state=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "    \n",
    "    for pixels in X_train:       \n",
    "        X_grey_train.append(pixels.copy())\n",
    "        \n",
    "    for pixels in X_validation:       \n",
    "        X_grey_validation.append(pixels.copy())\n",
    "        \n",
    "    for pixels in X_test:       \n",
    "        X_grey_test.append(pixels.copy())\n",
    "    \n",
    "    print(\"Finished \\n\")\n",
    "    return np.asarray(X_grey_train), np.asarray(X_grey_validation), np.asarray(X_grey_test), y_train, y_validation, y_test\n",
    "\n",
    "def get_youdens_index(predictions, Y):\n",
    "    # Calculate true positive/negative and false positive/negative\n",
    "    tp = sum((Y == predictions) * (Y == 1) * 1)\n",
    "    tn = sum((Y == predictions) * (Y == 0) * 1)\n",
    "    fp = sum((Y != predictions) * (Y == 0) * 1)\n",
    "    fn = sum((Y != predictions) * (Y == 1) * 1)\n",
    "    \n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (fp + tn)\n",
    "    \n",
    "    result = sensitivity - (1 - specificity)\n",
    "    # Put it in a dateframe for nicer visuals\n",
    "    df = pd.DataFrame({'Youdens Index': result})\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026b1420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Finished \n",
      "\n",
      "Hidden layers configurations test\n",
      "Hidden layers:  432\n",
      "Score:  0.9329472042771219 Time:  181.0083291530609\n",
      "     Youdens Index\n",
      "0         0.991976\n",
      "1         0.999888\n",
      "2         0.976530\n",
      "3         0.977387\n",
      "4         0.936952\n",
      "5         0.914005\n",
      "6         0.944000\n",
      "7         0.944882\n",
      "8         0.992313\n",
      "9         0.949944\n",
      "10        0.976134\n",
      "11        0.979798\n",
      "12        0.989417\n",
      "13        0.933165\n",
      "14        0.877358\n",
      "15        0.953376\n",
      "16        0.877529\n",
      "17        0.906780\n",
      "18        0.937931\n",
      "19        0.739496\n",
      "20        1.000000\n",
      "21        0.985555\n",
      "22        0.999663\n",
      "23        0.978861\n",
      "24        0.980956\n",
      "25        0.989474\n",
      "26        1.000000\n",
      "27        0.990465\n",
      "28        0.987938\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.994096\n",
      "32        0.991696\n",
      "33        0.990612\n",
      "34        0.714230\n",
      "35        0.818182\n",
      "36        0.949944\n",
      "37        0.983051\n",
      "38        0.984384\n",
      "39        0.951999\n",
      "40        0.999663\n",
      "41        1.000000\n",
      "42        0.897003\n",
      "43        0.999888\n",
      "44        1.000000\n",
      "45        0.968280\n",
      "46        0.947200\n",
      "47        0.999327\n",
      "48        1.000000\n",
      "49        0.966877\n",
      "50        0.959294\n",
      "51        0.999719\n",
      "52        0.984559\n",
      "53        0.982899\n",
      "54        1.000000\n",
      "55        0.937163\n",
      "56        0.833277\n",
      "57        0.953376\n",
      "58        0.928000\n",
      "59        0.850821\n",
      "60        0.994897\n",
      "61        0.895354\n",
      "62        0.846554\n",
      "63        0.891192\n",
      "64        0.946970\n",
      "65        0.981308\n",
      "66        0.999832\n",
      "67        0.974534\n",
      "68        0.980817\n",
      "69        0.962350\n",
      "70        0.891192\n",
      "71        0.992310\n",
      "72        0.994568\n",
      "73        0.677966\n",
      "74        0.846154\n",
      "75        0.922358\n",
      "76        0.991323\n",
      "77        0.975750\n",
      "78        0.858268\n",
      "79        0.928571\n",
      "80        0.999944\n",
      "81        0.978149\n",
      "82        0.965992\n",
      "83        0.988621\n",
      "84        0.999944\n",
      "85        0.999493\n",
      "86        0.963855\n",
      "87        0.839416\n",
      "88        0.965149\n",
      "89        0.956588\n",
      "90        0.977829\n",
      "91        0.897526\n",
      "92        1.000000\n",
      "93        0.993549\n",
      "94        0.959831\n",
      "95        0.993876\n",
      "96        0.999832\n",
      "97        0.984733\n",
      "98        0.866667\n",
      "99        0.967888\n",
      "100       0.926173\n",
      "101       0.967480\n",
      "102       0.999944\n",
      "103       0.999152\n",
      "104       0.948529\n",
      "105       0.990685\n",
      "106       0.773473\n",
      "107       0.844038\n",
      "108       0.798275\n",
      "109       0.803094\n",
      "110       0.992576\n",
      "111       0.944388\n",
      "112       0.976266\n",
      "113       1.000000\n",
      "114       0.941120\n",
      "115       0.992481\n",
      "116       0.960002\n",
      "117       1.000000\n",
      "118       0.937388\n",
      "119       0.974359\n",
      "120       0.986962\n",
      "121       0.990346\n",
      "122       0.992479\n",
      "123       0.964061\n",
      "124       0.999775\n",
      "125       0.991015\n",
      "126       0.775194\n",
      "127       0.991150\n",
      "128       0.988419\n",
      "129       0.985219 \n",
      "\n",
      "Hidden layers:  216\n",
      "Score:  0.875417687680998 Time:  56.913658142089844\n",
      "     Youdens Index\n",
      "0         0.999663\n",
      "1         0.990573\n",
      "2         0.882820\n",
      "3         0.997194\n",
      "4         0.997083\n",
      "5         0.892801\n",
      "6         0.999383\n",
      "7         0.936784\n",
      "8         0.976939\n",
      "9         0.966611\n",
      "10        0.936284\n",
      "11        0.969529\n",
      "12        0.988461\n",
      "13        0.762514\n",
      "14        0.990062\n",
      "15        0.937536\n",
      "16        0.884668\n",
      "17        0.940678\n",
      "18        0.937875\n",
      "19        0.856190\n",
      "20        0.999944\n",
      "21        0.934634\n",
      "22        0.884648\n",
      "23        0.950489\n",
      "24        0.885907\n",
      "25        0.962933\n",
      "26        0.999944\n",
      "27        0.966317\n",
      "28        0.967980\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.987798\n",
      "32        0.947537\n",
      "33        0.936671\n",
      "34        0.793314\n",
      "35        0.835579\n",
      "36        0.948935\n",
      "37        0.923673\n",
      "38        0.968768\n",
      "39        0.957725\n",
      "40        0.894625\n",
      "41        0.976992\n",
      "42        0.955323\n",
      "43        0.999103\n",
      "44        0.995895\n",
      "45        0.943704\n",
      "46        0.719298\n",
      "47        0.999888\n",
      "48        0.991879\n",
      "49        0.999215\n",
      "50        0.998878\n",
      "51        0.998766\n",
      "52        0.984167\n",
      "53        0.926773\n",
      "54        0.991758\n",
      "55        0.916386\n",
      "56        0.934345\n",
      "57        0.989331\n",
      "58        0.672000\n",
      "59        0.911328\n",
      "60        0.846550\n",
      "61        0.880148\n",
      "62        0.866105\n",
      "63        0.832491\n",
      "64        0.977104\n",
      "65        0.999720\n",
      "66        0.951164\n",
      "67        0.933436\n",
      "68        0.810314\n",
      "69        0.977219\n",
      "70        0.789855\n",
      "71        0.991805\n",
      "72        0.993837\n",
      "73        0.879562\n",
      "74        0.837214\n",
      "75        0.955663\n",
      "76        0.982647\n",
      "77        0.951108\n",
      "78        0.936840\n",
      "79        0.974901\n",
      "80        0.977759\n",
      "81        0.978205\n",
      "82        0.830913\n",
      "83        0.966932\n",
      "84        0.976370\n",
      "85        0.954433\n",
      "86        0.891398\n",
      "87        0.838518\n",
      "88        0.878613\n",
      "89        0.950845\n",
      "90        0.962899\n",
      "91        0.692913\n",
      "92        0.991133\n",
      "93        0.987211\n",
      "94        0.982520\n",
      "95        0.719045\n",
      "96        0.903280\n",
      "97        0.991974\n",
      "98        0.822166\n",
      "99        0.855720\n",
      "100       0.893218\n",
      "101       0.975554\n",
      "102       0.999720\n",
      "103       0.992170\n",
      "104       0.918444\n",
      "105       0.992884\n",
      "106       0.735065\n",
      "107       0.916743\n",
      "108       0.837027\n",
      "109       0.887296\n",
      "110       0.978066\n",
      "111       0.972054\n",
      "112       0.982513\n",
      "113       0.999832\n",
      "114       0.873669\n",
      "115       0.991640\n",
      "116       0.944080\n",
      "117       1.000000\n",
      "118       0.921370\n",
      "119       0.998818\n",
      "120       0.974261\n",
      "121       0.993679\n",
      "122       0.992423\n",
      "123       0.985265\n",
      "124       0.999888\n",
      "125       0.991015\n",
      "126       0.883384\n",
      "127       0.938053\n",
      "128       0.997525\n",
      "129       0.949640 \n",
      "\n",
      "Hidden layers:  (216, 108)\n",
      "Score:  0.9323345956783248 Time:  98.253178358078\n",
      "     Youdens Index\n",
      "0         1.000000\n",
      "1         0.954041\n",
      "2         0.815385\n",
      "3         0.925261\n",
      "4         0.858212\n",
      "5         0.991959\n",
      "6         1.000000\n",
      "7         0.976266\n",
      "8         0.969869\n",
      "9         0.966667\n",
      "10        0.928403\n",
      "11        0.999776\n",
      "12        0.989417\n",
      "13        0.933221\n",
      "14        0.971642\n",
      "15        0.976632\n",
      "16        0.963355\n",
      "17        0.982995\n",
      "18        0.882759\n",
      "19        0.856919\n",
      "20        0.991071\n",
      "21        0.927889\n",
      "22        0.914230\n",
      "23        0.992991\n",
      "24        0.948918\n",
      "25        0.957838\n",
      "26        1.000000\n",
      "27        0.990070\n",
      "28        0.979198\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.988248\n",
      "32        0.932724\n",
      "33        0.771654\n",
      "34        0.872679\n",
      "35        0.881706\n",
      "36        0.941667\n",
      "37        0.906780\n",
      "38        0.976744\n",
      "39        0.979340\n",
      "40        0.977444\n",
      "41        0.977273\n",
      "42        0.955882\n",
      "43        0.991963\n",
      "44        0.983749\n",
      "45        0.944770\n",
      "46        0.956084\n",
      "47        1.000000\n",
      "48        0.999944\n",
      "49        0.950764\n",
      "50        0.975498\n",
      "51        0.977275\n",
      "52        0.976755\n",
      "53        0.943033\n",
      "54        0.999607\n",
      "55        0.909610\n",
      "56        0.944332\n",
      "57        0.968824\n",
      "58        0.887888\n",
      "59        0.999271\n",
      "60        0.951389\n",
      "61        0.820896\n",
      "62        0.813109\n",
      "63        0.975735\n",
      "64        0.802862\n",
      "65        0.990654\n",
      "66        0.951220\n",
      "67        0.965821\n",
      "68        0.937769\n",
      "69        0.962350\n",
      "70        0.978093\n",
      "71        0.991805\n",
      "72        0.962766\n",
      "73        0.771074\n",
      "74        0.948326\n",
      "75        0.990987\n",
      "76        0.905172\n",
      "77        0.983703\n",
      "78        0.984140\n",
      "79        0.960149\n",
      "80        0.989133\n",
      "81        0.956297\n",
      "82        0.837838\n",
      "83        0.978142\n",
      "84        0.984116\n",
      "85        0.994781\n",
      "86        0.927711\n",
      "87        0.773330\n",
      "88        0.965318\n",
      "89        0.897297\n",
      "90        0.992310\n",
      "91        0.928853\n",
      "92        0.991525\n",
      "93        0.912088\n",
      "94        0.977143\n",
      "95        0.966292\n",
      "96        0.999944\n",
      "97        0.999663\n",
      "98        0.844388\n",
      "99        0.904000\n",
      "100       0.983046\n",
      "101       0.967424\n",
      "102       1.000000\n",
      "103       0.984849\n",
      "104       0.977099\n",
      "105       0.981369\n",
      "106       0.894882\n",
      "107       0.957839\n",
      "108       0.645161\n",
      "109       0.959957\n",
      "110       0.935658\n",
      "111       0.990685\n",
      "112       0.960237\n",
      "113       0.999944\n",
      "114       0.915742\n",
      "115       0.999888\n",
      "116       0.959776\n",
      "117       0.976378\n",
      "118       0.937276\n",
      "119       0.999887\n",
      "120       0.926717\n",
      "121       0.953704\n",
      "122       1.000000\n",
      "123       0.971429\n",
      "124       0.988644\n",
      "125       0.991015\n",
      "126       0.945288\n",
      "127       0.955752\n",
      "128       0.988363\n",
      "129       0.942109 \n",
      "\n",
      "Hidden layers:  108\n",
      "Score:  0.4545555803074181 Time:  130.7263903617859\n",
      "     Youdens Index\n",
      "0         0.622994\n",
      "1         0.947989\n",
      "2        -0.000168\n",
      "3         0.350185\n",
      "4         0.639556\n",
      "5         0.984943\n",
      "6         0.654710\n",
      "7         0.357493\n",
      "8         0.044832\n",
      "9         0.581483\n",
      "10        0.221101\n",
      "11        0.363076\n",
      "12        0.571770\n",
      "13        0.310438\n",
      "14        0.725855\n",
      "15        0.463265\n",
      "16        0.682611\n",
      "17        0.676172\n",
      "18        0.544435\n",
      "19        0.419888\n",
      "20        0.776730\n",
      "21        0.723476\n",
      "22        0.983357\n",
      "23        0.440593\n",
      "24        0.642086\n",
      "25        0.645680\n",
      "26        1.000000\n",
      "27        0.453849\n",
      "28        0.060661\n",
      "29        1.000000\n",
      "30        0.976370\n",
      "31        0.479476\n",
      "32        0.126529\n",
      "33        0.099782\n",
      "34        0.324443\n",
      "35        0.590517\n",
      "36        0.766442\n",
      "37        0.542093\n",
      "38        0.518370\n",
      "39        0.793454\n",
      "40        0.864381\n",
      "41        0.876745\n",
      "42        0.000000\n",
      "43        0.639167\n",
      "44        0.918238\n",
      "45        0.322498\n",
      "46        0.131355\n",
      "47        0.754845\n",
      "48        0.467349\n",
      "49        0.384797\n",
      "50        0.322399\n",
      "51        0.636573\n",
      "52        0.863958\n",
      "53        0.381777\n",
      "54        0.763387\n",
      "55        0.129923\n",
      "56        0.580476\n",
      "57        0.384512\n",
      "58        0.514897\n",
      "59        0.260804\n",
      "60        0.841783\n",
      "61        0.021322\n",
      "62        0.391536\n",
      "63        0.000000\n",
      "64        0.874748\n",
      "65        0.884769\n",
      "66        0.633867\n",
      "67        0.090853\n",
      "68        0.493798\n",
      "69        0.720458\n",
      "70       -0.000281\n",
      "71        0.327908\n",
      "72        0.568474\n",
      "73        0.439949\n",
      "74        0.230153\n",
      "75        0.513318\n",
      "76        0.353280\n",
      "77        0.402104\n",
      "78        0.469020\n",
      "79        0.117814\n",
      "80        0.621453\n",
      "81        0.303787\n",
      "82        0.328666\n",
      "83        0.555858\n",
      "84        0.610350\n",
      "85        0.392869\n",
      "86        0.795013\n",
      "87        0.572546\n",
      "88        0.441713\n",
      "89        0.175452\n",
      "90        0.550573\n",
      "91        0.361980\n",
      "92        0.880907\n",
      "93        0.344241\n",
      "94        0.729179\n",
      "95        0.336404\n",
      "96        0.571291\n",
      "97        0.847216\n",
      "98        0.658754\n",
      "99        0.463495\n",
      "100       0.515664\n",
      "101       0.848612\n",
      "102       0.903975\n",
      "103       0.900021\n",
      "104       0.425741\n",
      "105       0.341696\n",
      "106       0.065085\n",
      "107       0.474120\n",
      "108       0.055779\n",
      "109       0.068959\n",
      "110       0.838535\n",
      "111       0.814198\n",
      "112       0.078684\n",
      "113       0.999046\n",
      "114       0.739384\n",
      "115       0.900348\n",
      "116       0.107841\n",
      "117       0.944714\n",
      "118       0.413221\n",
      "119       0.701382\n",
      "120       0.681297\n",
      "121       0.766207\n",
      "122       0.962337\n",
      "123       0.968398\n",
      "124       0.958371\n",
      "125       0.802899\n",
      "126       0.336261\n",
      "127       0.326761\n",
      "128       0.398430\n",
      "129      -0.000056 \n",
      "\n",
      "Hidden layers:  (108, 54)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8665627088438405 Time:  67.73351287841797\n",
      "     Youdens Index\n",
      "0         0.969925\n",
      "1         0.972279\n",
      "2         0.806795\n",
      "3         0.923858\n",
      "4         0.999439\n",
      "5         0.970531\n",
      "6         0.967832\n",
      "7         0.724297\n",
      "8         0.953990\n",
      "9         0.949720\n",
      "10        0.928235\n",
      "11        0.969697\n",
      "12        0.915621\n",
      "13        0.710999\n",
      "14        0.933738\n",
      "15        0.922312\n",
      "16        0.920639\n",
      "17        0.915142\n",
      "18        0.813793\n",
      "19        0.704481\n",
      "20        0.999888\n",
      "21        0.820032\n",
      "22        0.806974\n",
      "23        0.882366\n",
      "24        0.961969\n",
      "25        0.988686\n",
      "26        1.000000\n",
      "27        0.928234\n",
      "28        0.881640\n",
      "29        1.000000\n",
      "30        0.992366\n",
      "31        0.952823\n",
      "32        0.842947\n",
      "33        0.905063\n",
      "34        0.761288\n",
      "35        0.872055\n",
      "36        0.907997\n",
      "37        0.889662\n",
      "38        0.813729\n",
      "39        0.938075\n",
      "40        0.932219\n",
      "41        0.954377\n",
      "42        0.823306\n",
      "43        0.944695\n",
      "44        0.995951\n",
      "45        0.967943\n",
      "46        0.929208\n",
      "47        0.982913\n",
      "48        0.975694\n",
      "49        0.885246\n",
      "50        0.918307\n",
      "51        0.954494\n",
      "52        0.992308\n",
      "53        0.983516\n",
      "54        0.991758\n",
      "55        0.840053\n",
      "56        0.795624\n",
      "57        0.796542\n",
      "58        0.815944\n",
      "59        0.841040\n",
      "60        0.870127\n",
      "61        0.945180\n",
      "62        0.620000\n",
      "63        0.948546\n",
      "64        0.984231\n",
      "65        0.934467\n",
      "66        0.914354\n",
      "67        0.925059\n",
      "68        0.866510\n",
      "69        0.887050\n",
      "70        0.840524\n",
      "71        0.923271\n",
      "72        0.882922\n",
      "73        0.745482\n",
      "74        0.717837\n",
      "75        0.877909\n",
      "76        1.000000\n",
      "77        0.943212\n",
      "78        0.920306\n",
      "79        0.888160\n",
      "80        0.992963\n",
      "81        0.971014\n",
      "82        0.783222\n",
      "83        0.960061\n",
      "84        0.961664\n",
      "85        0.902802\n",
      "86        0.831325\n",
      "87        0.794161\n",
      "88        0.882875\n",
      "89        0.928829\n",
      "90        0.830265\n",
      "91        0.842127\n",
      "92        0.991189\n",
      "93        0.965233\n",
      "94        0.976693\n",
      "95        0.936234\n",
      "96        0.999888\n",
      "97        0.992030\n",
      "98        0.836420\n",
      "99        0.927271\n",
      "100       0.909556\n",
      "101       0.967143\n",
      "102       0.957447\n",
      "103       0.954660\n",
      "104       0.939942\n",
      "105       0.897980\n",
      "106       0.593947\n",
      "107       0.794802\n",
      "108       0.652272\n",
      "109       0.691904\n",
      "110       0.971204\n",
      "111       0.907351\n",
      "112       0.896460\n",
      "113       0.992254\n",
      "114       0.923641\n",
      "115       0.962406\n",
      "116       0.855196\n",
      "117       0.991789\n",
      "118       0.906138\n",
      "119       0.984165\n",
      "120       0.931747\n",
      "121       0.833164\n",
      "122       0.992366\n",
      "123       0.992801\n",
      "124       0.971583\n",
      "125       0.981751\n",
      "126       0.689810\n",
      "127       0.928923\n",
      "128       0.920510\n",
      "129       0.891413 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test/Configure runs\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Call process_files and assign variables\n",
    "X_grey_train, X_grey_validation, X_grey_test, Y_train, Y_validation, Y_test = process_files(data_path)\n",
    "\n",
    "print(\"Hidden layers configurations test\")\n",
    "for hl in [(432), (216), (216, 108), (108), (108, 54)]:\n",
    "    print(\"Hidden layers: \", hl)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hl, max_iter=500, random_state = 1)\n",
    "    t0 = time.time()\n",
    "    mlp.fit(X_grey_train, Y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"Score: \", mlp.score(X_grey_validation, Y_validation), \"Time: \", t1 - t0)\n",
    "    print(get_youdens_index(mlp.predict(X_grey_validation), Y_validation), \"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab86f6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Tests\n",
      "Alpha:  0.0001\n",
      "Score:  0.9323345956783248 Time:  98.70219111442566\n",
      "     Youdens Index\n",
      "0         1.000000\n",
      "1         0.954041\n",
      "2         0.815385\n",
      "3         0.925261\n",
      "4         0.858212\n",
      "5         0.991959\n",
      "6         1.000000\n",
      "7         0.976266\n",
      "8         0.969869\n",
      "9         0.966667\n",
      "10        0.928403\n",
      "11        0.999776\n",
      "12        0.989417\n",
      "13        0.933221\n",
      "14        0.971642\n",
      "15        0.976632\n",
      "16        0.963355\n",
      "17        0.982995\n",
      "18        0.882759\n",
      "19        0.856919\n",
      "20        0.991071\n",
      "21        0.927889\n",
      "22        0.914230\n",
      "23        0.992991\n",
      "24        0.948918\n",
      "25        0.957838\n",
      "26        1.000000\n",
      "27        0.990070\n",
      "28        0.979198\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.988248\n",
      "32        0.932724\n",
      "33        0.771654\n",
      "34        0.872679\n",
      "35        0.881706\n",
      "36        0.941667\n",
      "37        0.906780\n",
      "38        0.976744\n",
      "39        0.979340\n",
      "40        0.977444\n",
      "41        0.977273\n",
      "42        0.955882\n",
      "43        0.991963\n",
      "44        0.983749\n",
      "45        0.944770\n",
      "46        0.956084\n",
      "47        1.000000\n",
      "48        0.999944\n",
      "49        0.950764\n",
      "50        0.975498\n",
      "51        0.977275\n",
      "52        0.976755\n",
      "53        0.943033\n",
      "54        0.999607\n",
      "55        0.909610\n",
      "56        0.944332\n",
      "57        0.968824\n",
      "58        0.887888\n",
      "59        0.999271\n",
      "60        0.951389\n",
      "61        0.820896\n",
      "62        0.813109\n",
      "63        0.975735\n",
      "64        0.802862\n",
      "65        0.990654\n",
      "66        0.951220\n",
      "67        0.965821\n",
      "68        0.937769\n",
      "69        0.962350\n",
      "70        0.978093\n",
      "71        0.991805\n",
      "72        0.962766\n",
      "73        0.771074\n",
      "74        0.948326\n",
      "75        0.990987\n",
      "76        0.905172\n",
      "77        0.983703\n",
      "78        0.984140\n",
      "79        0.960149\n",
      "80        0.989133\n",
      "81        0.956297\n",
      "82        0.837838\n",
      "83        0.978142\n",
      "84        0.984116\n",
      "85        0.994781\n",
      "86        0.927711\n",
      "87        0.773330\n",
      "88        0.965318\n",
      "89        0.897297\n",
      "90        0.992310\n",
      "91        0.928853\n",
      "92        0.991525\n",
      "93        0.912088\n",
      "94        0.977143\n",
      "95        0.966292\n",
      "96        0.999944\n",
      "97        0.999663\n",
      "98        0.844388\n",
      "99        0.904000\n",
      "100       0.983046\n",
      "101       0.967424\n",
      "102       1.000000\n",
      "103       0.984849\n",
      "104       0.977099\n",
      "105       0.981369\n",
      "106       0.894882\n",
      "107       0.957839\n",
      "108       0.645161\n",
      "109       0.959957\n",
      "110       0.935658\n",
      "111       0.990685\n",
      "112       0.960237\n",
      "113       0.999944\n",
      "114       0.915742\n",
      "115       0.999888\n",
      "116       0.959776\n",
      "117       0.976378\n",
      "118       0.937276\n",
      "119       0.999887\n",
      "120       0.926717\n",
      "121       0.953704\n",
      "122       1.000000\n",
      "123       0.971429\n",
      "124       0.988644\n",
      "125       0.991015\n",
      "126       0.945288\n",
      "127       0.955752\n",
      "128       0.988363\n",
      "129       0.942109 \n",
      "\n",
      "Alpha:  0.001\n",
      "Score:  0.9387948318110938 Time:  94.9842164516449\n",
      "     Youdens Index\n",
      "0         0.999719\n",
      "1         0.990741\n",
      "2         0.938462\n",
      "3         0.910336\n",
      "4         0.960518\n",
      "5         0.971316\n",
      "6         0.992000\n",
      "7         0.952700\n",
      "8         0.999944\n",
      "9         0.949888\n",
      "10        0.960093\n",
      "11        0.989675\n",
      "12        0.994681\n",
      "13        0.955331\n",
      "14        0.933850\n",
      "15        0.984496\n",
      "16        0.913613\n",
      "17        0.957627\n",
      "18        0.917073\n",
      "19        0.789860\n",
      "20        0.999888\n",
      "21        0.956273\n",
      "22        0.998765\n",
      "23        0.992149\n",
      "24        0.917665\n",
      "25        0.968308\n",
      "26        1.000000\n",
      "27        0.985669\n",
      "28        0.948473\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.976608\n",
      "32        0.925205\n",
      "33        0.975481\n",
      "34        0.817348\n",
      "35        0.908082\n",
      "36        0.949944\n",
      "37        0.948984\n",
      "38        0.953376\n",
      "39        0.979340\n",
      "40        0.977388\n",
      "41        0.999831\n",
      "42        0.896947\n",
      "43        0.945144\n",
      "44        0.999887\n",
      "45        0.921204\n",
      "46        0.991004\n",
      "47        1.000000\n",
      "48        0.991879\n",
      "49        0.901639\n",
      "50        0.982843\n",
      "51        0.954831\n",
      "52        0.992252\n",
      "53        0.983628\n",
      "54        0.983572\n",
      "55        0.860999\n",
      "56        0.925646\n",
      "57        0.922368\n",
      "58        0.871664\n",
      "59        0.955860\n",
      "60        0.983366\n",
      "61        0.999102\n",
      "62        0.979775\n",
      "63        0.948883\n",
      "64        0.977273\n",
      "65        0.999888\n",
      "66        0.890188\n",
      "67        0.958566\n",
      "68        0.909953\n",
      "69        0.969925\n",
      "70        0.948995\n",
      "71        0.984284\n",
      "72        0.920213\n",
      "73        0.804973\n",
      "74        0.922516\n",
      "75        0.931034\n",
      "76        0.974082\n",
      "77        0.943436\n",
      "78        0.991958\n",
      "79        0.920523\n",
      "80        0.999550\n",
      "81        0.985339\n",
      "82        0.911994\n",
      "83        0.961692\n",
      "84        0.999944\n",
      "85        0.994724\n",
      "86        0.903559\n",
      "87        0.686075\n",
      "88        0.976541\n",
      "89        0.972635\n",
      "90        0.940896\n",
      "91        0.952475\n",
      "92        0.991469\n",
      "93        0.972077\n",
      "94        0.994286\n",
      "95        0.988539\n",
      "96        0.999102\n",
      "97        0.976987\n",
      "98        0.903648\n",
      "99        0.991944\n",
      "100       0.958904\n",
      "101       0.975498\n",
      "102       1.000000\n",
      "103       0.977358\n",
      "104       0.955546\n",
      "105       0.953648\n",
      "106       0.716701\n",
      "107       0.885134\n",
      "108       0.790210\n",
      "109       0.928573\n",
      "110       0.892857\n",
      "111       0.953704\n",
      "112       0.866142\n",
      "113       0.992366\n",
      "114       0.957983\n",
      "115       0.984962\n",
      "116       0.920792\n",
      "117       1.000000\n",
      "118       0.992075\n",
      "119       0.994815\n",
      "120       0.993621\n",
      "121       0.995145\n",
      "122       0.992647\n",
      "123       0.978515\n",
      "124       0.994350\n",
      "125       0.982143\n",
      "126       0.990902\n",
      "127       0.999888\n",
      "128       0.982995\n",
      "129       0.935196 \n",
      "\n",
      "Alpha:  0.01\n",
      "Score:  0.9356204054355091 Time:  120.81104922294617\n",
      "     Youdens Index\n",
      "0         0.999383\n",
      "1         0.981258\n",
      "2         0.876586\n",
      "3         0.990349\n",
      "4         0.975817\n",
      "5         0.992633\n",
      "6         0.999888\n",
      "7         0.991733\n",
      "8         0.992425\n",
      "9         0.983333\n",
      "10        0.944388\n",
      "11        0.999944\n",
      "12        0.994512\n",
      "13        0.947811\n",
      "14        0.990566\n",
      "15        0.999832\n",
      "16        0.906306\n",
      "17        0.966046\n",
      "18        0.875806\n",
      "19        0.915518\n",
      "20        0.999944\n",
      "21        0.892030\n",
      "22        0.991959\n",
      "23        0.985645\n",
      "24        0.999326\n",
      "25        0.999606\n",
      "26        1.000000\n",
      "27        0.919319\n",
      "28        0.974377\n",
      "29        1.000000\n",
      "30        0.999944\n",
      "31        0.993927\n",
      "32        0.984850\n",
      "33        0.999888\n",
      "34        0.872848\n",
      "35        0.890741\n",
      "36        0.941667\n",
      "37        0.915254\n",
      "38        0.922481\n",
      "39        0.958792\n",
      "40        0.954887\n",
      "41        0.988580\n",
      "42        0.985015\n",
      "43        0.999215\n",
      "44        0.999944\n",
      "45        0.928966\n",
      "46        0.815789\n",
      "47        0.974790\n",
      "48        0.959677\n",
      "49        0.991803\n",
      "50        0.747967\n",
      "51        1.000000\n",
      "52        0.961538\n",
      "53        0.983516\n",
      "54        1.000000\n",
      "55        0.930387\n",
      "56        0.870258\n",
      "57        0.914448\n",
      "58        0.888000\n",
      "59        0.762934\n",
      "60        0.991375\n",
      "61        0.977500\n",
      "62        0.852996\n",
      "63        0.956185\n",
      "64        0.909035\n",
      "65        0.999944\n",
      "66        0.963415\n",
      "67        0.942093\n",
      "68        0.957233\n",
      "69        0.984850\n",
      "70        0.985395\n",
      "71        0.976707\n",
      "72        0.951959\n",
      "73        0.805085\n",
      "74        0.957097\n",
      "75        0.810233\n",
      "76        1.000000\n",
      "77        0.999776\n",
      "78        0.936952\n",
      "79        0.880952\n",
      "80        0.999719\n",
      "81        0.992698\n",
      "82        0.945834\n",
      "83        0.988227\n",
      "84        0.999776\n",
      "85        0.914141\n",
      "86        0.915607\n",
      "87        0.955755\n",
      "88        0.952970\n",
      "89        0.940259\n",
      "90        0.963179\n",
      "91        0.928293\n",
      "92        0.889831\n",
      "93        0.966808\n",
      "94        0.891429\n",
      "95        0.960618\n",
      "96        0.965517\n",
      "97        0.998654\n",
      "98        0.881425\n",
      "99        0.863944\n",
      "100       0.991803\n",
      "101       0.983684\n",
      "102       1.000000\n",
      "103       0.992453\n",
      "104       0.999776\n",
      "105       0.999664\n",
      "106       0.801551\n",
      "107       0.926173\n",
      "108       0.886368\n",
      "109       0.967326\n",
      "110       0.985714\n",
      "111       0.962963\n",
      "112       0.983747\n",
      "113       0.992366\n",
      "114       0.941120\n",
      "115       0.999944\n",
      "116       0.930580\n",
      "117       0.984252\n",
      "118       0.937444\n",
      "119       0.943590\n",
      "120       0.968838\n",
      "121       0.990515\n",
      "122       0.999776\n",
      "123       0.978571\n",
      "124       0.994350\n",
      "125       0.999944\n",
      "126       0.968768\n",
      "127       1.000000\n",
      "128       0.982995\n",
      "129       0.920639 \n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.926654043216752 Time:  76.47727036476135\n",
      "     Youdens Index\n",
      "0         0.999944\n",
      "1         0.899944\n",
      "2         0.946042\n",
      "3         0.850578\n",
      "4         0.976210\n",
      "5         0.992633\n",
      "6         0.983944\n",
      "7         0.991958\n",
      "8         0.932275\n",
      "9         0.916667\n",
      "10        0.960205\n",
      "11        0.969641\n",
      "12        0.999606\n",
      "13        0.970090\n",
      "14        0.971530\n",
      "15        0.984440\n",
      "16        0.827282\n",
      "17        0.999159\n",
      "18        0.882759\n",
      "19        0.806667\n",
      "20        0.999776\n",
      "21        0.892030\n",
      "22        0.998765\n",
      "23        0.992935\n",
      "24        0.879634\n",
      "25        0.993724\n",
      "26        0.999888\n",
      "27        0.962029\n",
      "28        0.978916\n",
      "29        1.000000\n",
      "30        0.977099\n",
      "31        0.998819\n",
      "32        0.969981\n",
      "33        0.881834\n",
      "34        0.595070\n",
      "35        0.916389\n",
      "36        0.949383\n",
      "37        0.923673\n",
      "38        0.960792\n",
      "39        0.924321\n",
      "40        0.984962\n",
      "41        0.988355\n",
      "42        0.984959\n",
      "43        0.992188\n",
      "44        0.995951\n",
      "45        0.936896\n",
      "46        0.999552\n",
      "47        0.999551\n",
      "48        0.999327\n",
      "49        0.942623\n",
      "50        0.894197\n",
      "51        0.984962\n",
      "52        0.992139\n",
      "53        0.991590\n",
      "54        0.999832\n",
      "55        0.930275\n",
      "56        0.879630\n",
      "57        0.983935\n",
      "58        0.991776\n",
      "59        0.912169\n",
      "60        0.998991\n",
      "61        0.984345\n",
      "62        0.939832\n",
      "63        0.905124\n",
      "64        0.969697\n",
      "65        0.990542\n",
      "66        0.963303\n",
      "67        0.999720\n",
      "68        0.970662\n",
      "69        0.984570\n",
      "70        0.999607\n",
      "71        0.954086\n",
      "72        0.898936\n",
      "73        0.889550\n",
      "74        0.905871\n",
      "75        0.767129\n",
      "76        0.999888\n",
      "77        0.983815\n",
      "78        0.976266\n",
      "79        0.991503\n",
      "80        0.994370\n",
      "81        0.992249\n",
      "82        0.939133\n",
      "83        0.977973\n",
      "84        0.977099\n",
      "85        0.989505\n",
      "86        0.915663\n",
      "87        0.867996\n",
      "88        0.947752\n",
      "89        0.907939\n",
      "90        0.999439\n",
      "91        0.858212\n",
      "92        0.990853\n",
      "93        0.977122\n",
      "94        0.965546\n",
      "95        0.960224\n",
      "96        0.999663\n",
      "97        0.961776\n",
      "98        0.925421\n",
      "99        0.999607\n",
      "100       0.926005\n",
      "101       0.983684\n",
      "102       1.000000\n",
      "103       0.962151\n",
      "104       0.985126\n",
      "105       0.972110\n",
      "106       0.914198\n",
      "107       0.950427\n",
      "108       0.854054\n",
      "109       0.755737\n",
      "110       0.971316\n",
      "111       0.990629\n",
      "112       0.944601\n",
      "113       0.992310\n",
      "114       0.924314\n",
      "115       0.999832\n",
      "116       0.960058\n",
      "117       0.976322\n",
      "118       0.773381\n",
      "119       0.999718\n",
      "120       0.914522\n",
      "121       0.984702\n",
      "122       0.999888\n",
      "123       0.964173\n",
      "124       0.982995\n",
      "125       0.999608\n",
      "126       0.983318\n",
      "127       0.990982\n",
      "128       0.971639\n",
      "129       0.992301 \n",
      "\n",
      "Alpha:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9418578748050791 Time:  123.80176901817322\n",
      "     Youdens Index\n",
      "0         0.999383\n",
      "1         0.881818\n",
      "2         0.922740\n",
      "3         0.955168\n",
      "4         0.913330\n",
      "5         0.956694\n",
      "6         0.999888\n",
      "7         0.913386\n",
      "8         0.894737\n",
      "9         0.949888\n",
      "10        0.896825\n",
      "11        0.949327\n",
      "12        0.999550\n",
      "13        0.962851\n",
      "14        1.000000\n",
      "15        0.992248\n",
      "16        0.963804\n",
      "17        0.982995\n",
      "18        0.889655\n",
      "19        0.899104\n",
      "20        0.999776\n",
      "21        0.983984\n",
      "22        0.985714\n",
      "23        0.972302\n",
      "24        0.847989\n",
      "25        0.999887\n",
      "26        0.979167\n",
      "27        0.957346\n",
      "28        0.999718\n",
      "29        0.999944\n",
      "30        0.984733\n",
      "31        0.999944\n",
      "32        0.910392\n",
      "33        0.944882\n",
      "34        0.975293\n",
      "35        0.899888\n",
      "36        0.966611\n",
      "37        0.991133\n",
      "38        0.999944\n",
      "39        0.979396\n",
      "40        0.887218\n",
      "41        0.999775\n",
      "42        0.867647\n",
      "43        0.999103\n",
      "44        0.991903\n",
      "45        1.000000\n",
      "46        1.000000\n",
      "47        1.000000\n",
      "48        0.983871\n",
      "49        0.983494\n",
      "50        0.975385\n",
      "51        0.977444\n",
      "52        0.992308\n",
      "53        0.999944\n",
      "54        0.691057\n",
      "55        0.944444\n",
      "56        0.953704\n",
      "57        0.992080\n",
      "58        0.895944\n",
      "59        0.745614\n",
      "60        0.959621\n",
      "61        0.873078\n",
      "62        0.933333\n",
      "63        0.688406\n",
      "64        1.000000\n",
      "65        1.000000\n",
      "66        0.939024\n",
      "67        0.999664\n",
      "68        0.900418\n",
      "69        0.992369\n",
      "70        0.956409\n",
      "71        0.984621\n",
      "72        0.973404\n",
      "73        0.889831\n",
      "74        0.948662\n",
      "75        0.974026\n",
      "76        0.991379\n",
      "77        0.999888\n",
      "78        0.944882\n",
      "79        0.944444\n",
      "80        0.999887\n",
      "81        0.999832\n",
      "82        0.891780\n",
      "83        0.988959\n",
      "84        0.961832\n",
      "85        0.999662\n",
      "86        0.987952\n",
      "87        0.802807\n",
      "88        0.919075\n",
      "89        0.988795\n",
      "90        0.955882\n",
      "91        0.960574\n",
      "92        0.957627\n",
      "93        0.988898\n",
      "94        0.902857\n",
      "95        0.949438\n",
      "96        0.999607\n",
      "97        0.992254\n",
      "98        0.918462\n",
      "99        0.991439\n",
      "100       0.942567\n",
      "101       0.999888\n",
      "102       0.999832\n",
      "103       0.995887\n",
      "104       0.999944\n",
      "105       0.888889\n",
      "106       0.886120\n",
      "107       0.876881\n",
      "108       0.572581\n",
      "109       0.936727\n",
      "110       0.971429\n",
      "111       0.962963\n",
      "112       0.952700\n",
      "113       0.992366\n",
      "114       0.974734\n",
      "115       0.969925\n",
      "116       0.989592\n",
      "117       0.976378\n",
      "118       0.945256\n",
      "119       0.994872\n",
      "120       0.926492\n",
      "121       0.930556\n",
      "122       0.992591\n",
      "123       0.978571\n",
      "124       0.994182\n",
      "125       0.991071\n",
      "126       0.891473\n",
      "127       0.991094\n",
      "128       0.999944\n",
      "129       0.985612 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default alpha=0.0001\n",
    "# HL (216, 108) appears perform the best, use that for alpha tests\n",
    "print(\"Alpha Tests\")\n",
    "for a in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "    print(\"Alpha: \", a)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(216, 108), alpha=a, max_iter=500, random_state = 1)\n",
    "    t0 = time.time()\n",
    "    mlp.fit(X_grey_train, Y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"Score: \", mlp.score(X_grey_validation, Y_validation), \"Time: \", t1 - t0)\n",
    "    print(get_youdens_index(mlp.predict(X_grey_validation), Y_validation), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "637e1b91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to fit model ... \n",
      "\n",
      "Grey model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       101\n",
      "           1       1.00      0.88      0.94       110\n",
      "           2       0.98      0.88      0.93       113\n",
      "           3       0.99      0.95      0.97       131\n",
      "           4       0.98      0.92      0.95        93\n",
      "           5       0.97      0.98      0.97        99\n",
      "           6       0.89      1.00      0.94        98\n",
      "           7       1.00      0.94      0.97       117\n",
      "           8       1.00      0.90      0.95       105\n",
      "           9       0.98      0.91      0.95        94\n",
      "          10       1.00      0.90      0.95        88\n",
      "          11       1.00      0.98      0.99       133\n",
      "          12       0.95      0.98      0.97       131\n",
      "          13       0.99      0.96      0.97       114\n",
      "          14       0.97      1.00      0.98        88\n",
      "          15       0.98      0.98      0.98       100\n",
      "          16       0.99      0.94      0.96        98\n",
      "          17       0.98      0.95      0.96        97\n",
      "          18       0.99      0.93      0.96       107\n",
      "          19       0.97      0.89      0.93        93\n",
      "          20       0.98      1.00      0.99        96\n",
      "          21       0.80      0.98      0.88       115\n",
      "          22       1.00      0.97      0.99       108\n",
      "          23       0.98      1.00      0.99        94\n",
      "          24       0.95      0.83      0.89       108\n",
      "          25       0.99      1.00      1.00       151\n",
      "          26       1.00      0.99      1.00       102\n",
      "          27       1.00      0.98      0.99       131\n",
      "          28       0.96      0.99      0.98       149\n",
      "          29       1.00      1.00      1.00       116\n",
      "          30       1.00      1.00      1.00       109\n",
      "          31       0.98      1.00      0.99        94\n",
      "          32       0.99      0.96      0.97        98\n",
      "          33       1.00      0.92      0.96       119\n",
      "          34       0.87      0.95      0.91       109\n",
      "          35       0.97      0.99      0.98        95\n",
      "          36       0.98      0.94      0.96       100\n",
      "          37       0.90      1.00      0.95        64\n",
      "          38       1.00      1.00      1.00       116\n",
      "          39       1.00      1.00      1.00       107\n",
      "          40       1.00      0.86      0.93        96\n",
      "          41       0.94      1.00      0.97       154\n",
      "          42       1.00      0.91      0.96        70\n",
      "          43       0.94      0.98      0.96       101\n",
      "          44       1.00      0.99      1.00       208\n",
      "          45       1.00      0.97      0.99       108\n",
      "          46       1.00      0.98      0.99       102\n",
      "          47       1.00      1.00      1.00       119\n",
      "          48       1.00      1.00      1.00       105\n",
      "          49       1.00      1.00      1.00       113\n",
      "          50       0.98      0.99      0.99       112\n",
      "          51       1.00      0.99      1.00       116\n",
      "          52       1.00      0.98      0.99        98\n",
      "          53       1.00      0.96      0.98       109\n",
      "          54       1.00      0.77      0.87       110\n",
      "          55       1.00      0.95      0.97        94\n",
      "          56       1.00      0.96      0.98       114\n",
      "          57       0.98      0.95      0.97       105\n",
      "          58       1.00      0.90      0.95        99\n",
      "          59       1.00      0.74      0.85        92\n",
      "          60       0.98      0.95      0.97       102\n",
      "          61       0.98      0.84      0.90        98\n",
      "          62       1.00      0.96      0.98        99\n",
      "          63       1.00      0.66      0.79       102\n",
      "          64       0.98      0.99      0.99       100\n",
      "          65       0.99      0.99      0.99       100\n",
      "          66       1.00      0.95      0.98        65\n",
      "          67       0.96      0.97      0.97       105\n",
      "          68       1.00      0.93      0.96       152\n",
      "          69       1.00      0.98      0.99       107\n",
      "          70       0.98      0.98      0.98       109\n",
      "          71       0.98      1.00      0.99        95\n",
      "          72       1.00      0.94      0.97       135\n",
      "          73       1.00      0.89      0.94       123\n",
      "          74       1.00      0.94      0.97        79\n",
      "          75       0.93      0.94      0.93        96\n",
      "          76       1.00      1.00      1.00       106\n",
      "          77       0.97      0.95      0.96       104\n",
      "          78       1.00      0.99      0.99        96\n",
      "          79       0.98      0.92      0.95       100\n",
      "          80       1.00      0.99      0.99       163\n",
      "          81       1.00      1.00      1.00       116\n",
      "          82       1.00      0.88      0.94       118\n",
      "          83       0.97      0.99      0.98       156\n",
      "          84       1.00      0.98      0.99        95\n",
      "          85       0.96      0.99      0.98       159\n",
      "          86       1.00      0.99      0.99        69\n",
      "          87       0.97      0.86      0.91       110\n",
      "          88       1.00      0.95      0.97       143\n",
      "          89       0.95      0.99      0.97       145\n",
      "          90       0.99      0.96      0.97        96\n",
      "          91       0.96      0.95      0.96       107\n",
      "          92       1.00      0.90      0.95        88\n",
      "          93       0.98      0.99      0.98       160\n",
      "          94       1.00      0.91      0.96       141\n",
      "          95       0.99      0.96      0.98       153\n",
      "          96       0.95      1.00      0.97        95\n",
      "          97       0.98      0.99      0.99       123\n",
      "          98       1.00      0.94      0.97       101\n",
      "          99       0.93      0.99      0.96       109\n",
      "         100       1.00      0.95      0.97        97\n",
      "         101       0.95      0.97      0.96        78\n",
      "         102       0.98      1.00      0.99        84\n",
      "         103       0.98      0.99      0.99       197\n",
      "         104       0.99      1.00      0.99        90\n",
      "         105       1.00      0.88      0.93        90\n",
      "         106       0.88      0.89      0.88        80\n",
      "         107       0.98      0.89      0.93        90\n",
      "         108       1.00      0.49      0.66       104\n",
      "         109       0.97      0.94      0.95        93\n",
      "         110       1.00      0.96      0.98       118\n",
      "         111       1.00      0.98      0.99       129\n",
      "         112       1.00      0.94      0.97       124\n",
      "         113       1.00      0.99      1.00       105\n",
      "         114       0.97      0.97      0.97       105\n",
      "         115       1.00      0.98      0.99        98\n",
      "         116       0.93      0.96      0.94       156\n",
      "         117       1.00      0.98      0.99        88\n",
      "         118       1.00      0.91      0.95       120\n",
      "         119       1.00      0.99      1.00       140\n",
      "         120       0.99      0.95      0.97       163\n",
      "         121       0.99      0.95      0.97       146\n",
      "         122       0.99      0.98      0.98        98\n",
      "         123       1.00      1.00      1.00        92\n",
      "         124       0.99      1.00      0.99       147\n",
      "         125       1.00      0.99      0.99        71\n",
      "         126       0.97      0.91      0.94        85\n",
      "         127       0.97      1.00      0.99       101\n",
      "         128       0.99      0.99      0.99       141\n",
      "         129       1.00      0.98      0.99        99\n",
      "\n",
      "   micro avg       0.98      0.95      0.97     14365\n",
      "   macro avg       0.98      0.95      0.96     14365\n",
      "weighted avg       0.98      0.95      0.97     14365\n",
      " samples avg       0.95      0.95      0.95     14365\n",
      "\n",
      "     Youdens Index\n",
      "0         0.999579\n",
      "1         0.881818\n",
      "2         0.875966\n",
      "3         0.954128\n",
      "4         0.924591\n",
      "5         0.979588\n",
      "6         0.999159\n",
      "7         0.940171\n",
      "8         0.904762\n",
      "9         0.914753\n",
      "10        0.897727\n",
      "11        0.977444\n",
      "12        0.984241\n",
      "13        0.956070\n",
      "14        0.999790\n",
      "15        0.979860\n",
      "16        0.938705\n",
      "17        0.948313\n",
      "18        0.925164\n",
      "19        0.892263\n",
      "20        0.999860\n",
      "21        0.980574\n",
      "22        0.972222\n",
      "23        0.999860\n",
      "24        0.832983\n",
      "25        0.999930\n",
      "26        0.990196\n",
      "27        0.977099\n",
      "28        0.992867\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.999860\n",
      "32        0.959114\n",
      "33        0.924370\n",
      "34        0.953006\n",
      "35        0.989263\n",
      "36        0.939860\n",
      "37        0.999511\n",
      "38        1.000000\n",
      "39        1.000000\n",
      "40        0.864583\n",
      "41        0.999367\n",
      "42        0.914286\n",
      "43        0.979777\n",
      "44        0.990385\n",
      "45        0.972222\n",
      "46        0.980392\n",
      "47        1.000000\n",
      "48        1.000000\n",
      "49        1.000000\n",
      "50        0.990931\n",
      "51        0.991379\n",
      "52        0.979592\n",
      "53        0.963303\n",
      "54        0.772727\n",
      "55        0.946809\n",
      "56        0.964912\n",
      "57        0.952241\n",
      "58        0.898990\n",
      "59        0.739130\n",
      "60        0.950840\n",
      "61        0.836595\n",
      "62        0.959596\n",
      "63        0.656863\n",
      "64        0.989860\n",
      "65        0.989930\n",
      "66        0.953846\n",
      "67        0.971148\n",
      "68        0.927632\n",
      "69        0.981308\n",
      "70        0.981511\n",
      "71        0.999860\n",
      "72        0.940741\n",
      "73        0.894309\n",
      "74        0.936709\n",
      "75        0.937009\n",
      "76        1.000000\n",
      "77        0.951713\n",
      "78        0.989583\n",
      "79        0.919860\n",
      "80        0.987730\n",
      "81        1.000000\n",
      "82        0.881356\n",
      "83        0.986898\n",
      "84        0.978947\n",
      "85        0.993288\n",
      "86        0.985507\n",
      "87        0.863426\n",
      "88        0.951049\n",
      "89        0.985715\n",
      "90        0.958263\n",
      "91        0.952990\n",
      "92        0.897727\n",
      "93        0.987289\n",
      "94        0.914894\n",
      "95        0.960714\n",
      "96        0.999650\n",
      "97        0.991729\n",
      "98        0.940594\n",
      "99        0.990265\n",
      "100       0.948454\n",
      "101       0.974079\n",
      "102       0.999860\n",
      "103       0.994642\n",
      "104       0.999930\n",
      "105       0.877778\n",
      "106       0.886800\n",
      "107       0.888749\n",
      "108       0.490385\n",
      "109       0.935274\n",
      "110       0.957627\n",
      "111       0.984496\n",
      "112       0.935484\n",
      "113       0.990476\n",
      "114       0.971218\n",
      "115       0.979592\n",
      "116       0.960694\n",
      "117       0.977273\n",
      "118       0.908333\n",
      "119       0.992857\n",
      "120       0.950779\n",
      "121       0.945135\n",
      "122       0.979522\n",
      "123       1.000000\n",
      "124       0.999859\n",
      "125       0.985915\n",
      "126       0.905742\n",
      "127       0.999790\n",
      "128       0.985745\n",
      "129       0.979798 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HL (216, 108) and alpha=1 seems to be the best based on results above.\n",
    "# Train the model with this and let's finally see how it performs on test.\n",
    "print('Beginning to fit model ... \\n')\n",
    "mlpc_grey =  MLPClassifier(hidden_layer_sizes=(216, 108), alpha=1, activation='relu', solver='adam', random_state=1, max_iter=500)\n",
    "mlpc_grey.fit(X_grey_train, Y_train)\n",
    "grey_test_result = mlpc_grey.predict(X_grey_test)\n",
    "\n",
    "print(\"Grey model\")\n",
    "print(classification_report(Y_test, grey_test_result, zero_division=0))\n",
    "print(get_youdens_index(grey_test_result, Y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1eb45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
