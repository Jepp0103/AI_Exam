{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329f6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Path to images\n",
    "data_path = fr'../Datasets/Training'\n",
    "\n",
    "def remove_white_background(pixels):\n",
    "    newPixels = []\n",
    "    for pixel in pixels:\n",
    "        pixel = list(pixel)\n",
    "        if ((256 > pixel[0] > 200) and (256 > pixel[1] > 200) and (256 > pixel[2] > 200)):\n",
    "            pixel[0] = 0\n",
    "            pixel[1] = 0\n",
    "            pixel[2] = 0\n",
    "        newPixels.append(pixel)\n",
    "    \n",
    "    return newPixels\n",
    "\n",
    "def grayscale(pixels):\n",
    "    newPixels = []\n",
    "    for pixel in pixels:\n",
    "        pixel = tuple(pixel)\n",
    "        newPixels.append(pixel)\n",
    "    \n",
    "    newImg = Image.new(\"RGB\", (24,24))\n",
    "    newImg.putdata(newPixels)\n",
    "    greyImg = newImg.convert('L')\n",
    "    return list(greyImg.getdata())\n",
    "\n",
    "def get_rgb_pixels_onehot_labels(src):\n",
    "    print(\"Starting...\")\n",
    "    newPixels = []\n",
    "    y = np.empty(shape=[0, 1])\n",
    "\n",
    "    for subdir in os.listdir(src):\n",
    "        current_path = os.path.join(src, subdir)\n",
    "        for file in os.listdir(current_path):\n",
    "            img = Image.open(os.path.join(current_path, file))\n",
    "            imgResize = img.resize((24,24))\n",
    "            pixels = list(imgResize.getdata())\n",
    "            pixels = remove_white_background(pixels)\n",
    "            pixels = grayscale(pixels)\n",
    "            newPixels.append(pixels)\n",
    "            y = np.append(y, subdir)\n",
    "    return newPixels, LabelBinarizer().fit_transform(y) # OneHot encode y\n",
    "\n",
    "def process_files(src):\n",
    "    X_grey_train = []\n",
    "    X_grey_validation = []\n",
    "    X_grey_test = []\n",
    "    all_pixels, y = get_rgb_pixels_onehot_labels(src)\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(all_pixels, y, test_size=0.2, random_state=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "    \n",
    "    for pixels in X_train:       \n",
    "        X_grey_train.append(pixels.copy())\n",
    "        \n",
    "    for pixels in X_validation:       \n",
    "        X_grey_validation.append(pixels.copy())\n",
    "        \n",
    "    for pixels in X_test:       \n",
    "        X_grey_test.append(pixels.copy())\n",
    "    \n",
    "    print(\"Finished \\n\")\n",
    "    return np.asarray(X_grey_train), np.asarray(X_grey_validation), np.asarray(X_grey_test), y_train, y_validation, y_test\n",
    "\n",
    "def get_youdens_index(predictions, Y):\n",
    "    # Calculate true positive/negative and false positive/negative\n",
    "    tp = sum((Y == predictions) * (Y == 1) * 1)\n",
    "    tn = sum((Y == predictions) * (Y == 0) * 1)\n",
    "    fp = sum((Y != predictions) * (Y == 0) * 1)\n",
    "    fn = sum((Y != predictions) * (Y == 1) * 1)\n",
    "    \n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (fp + tn)\n",
    "    \n",
    "    result = sensitivity - (1 - specificity)\n",
    "    # Put it in a dateframe for nicer visuals\n",
    "    df = pd.DataFrame({'Youdens Index': result})\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026b1420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Finished \n",
      "\n",
      "Hidden layers configurations test\n",
      "Hidden layers:  432\n",
      "Score:  0.9497104032078414 Time:  383.7857594490051\n",
      "     Youdens Index\n",
      "0         0.917293\n",
      "1         0.981762\n",
      "2         0.968950\n",
      "3         0.999607\n",
      "4         0.921260\n",
      "5         0.999944\n",
      "6         0.976000\n",
      "7         0.968504\n",
      "8         0.999383\n",
      "9         0.975000\n",
      "10        0.952381\n",
      "11        0.959596\n",
      "12        1.000000\n",
      "13        0.990741\n",
      "14        0.999944\n",
      "15        0.930233\n",
      "16        0.956554\n",
      "17        0.940510\n",
      "18        0.937819\n",
      "19        0.873950\n",
      "20        1.000000\n",
      "21        0.956778\n",
      "22        0.928571\n",
      "23        0.875862\n",
      "24        0.993671\n",
      "25        0.984211\n",
      "26        1.000000\n",
      "27        0.900474\n",
      "28        0.954025\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.999775\n",
      "32        0.887947\n",
      "33        0.976154\n",
      "34        0.888777\n",
      "35        0.863580\n",
      "36        0.950000\n",
      "37        0.982883\n",
      "38        0.984440\n",
      "39        0.979171\n",
      "40        0.992481\n",
      "41        0.988580\n",
      "42        0.882241\n",
      "43        0.999720\n",
      "44        1.000000\n",
      "45        0.952756\n",
      "46        0.973684\n",
      "47        0.999888\n",
      "48        0.967742\n",
      "49        0.966989\n",
      "50        0.967480\n",
      "51        0.992369\n",
      "52        0.992252\n",
      "53        0.967480\n",
      "54        0.999888\n",
      "55        0.979111\n",
      "56        0.907351\n",
      "57        0.945736\n",
      "58        0.919551\n",
      "59        0.955916\n",
      "60        0.806396\n",
      "61        0.999102\n",
      "62        0.959719\n",
      "63        0.811538\n",
      "64        0.969697\n",
      "65        0.990654\n",
      "66        0.999944\n",
      "67        0.966886\n",
      "68        0.976247\n",
      "69        0.984906\n",
      "70        0.978149\n",
      "71        0.976987\n",
      "72        0.994568\n",
      "73        0.923224\n",
      "74        0.974079\n",
      "75        0.879310\n",
      "76        0.991099\n",
      "77        0.983759\n",
      "78        0.976154\n",
      "79        0.968254\n",
      "80        0.999831\n",
      "81        0.978261\n",
      "82        0.931702\n",
      "83        0.967157\n",
      "84        0.984733\n",
      "85        0.964534\n",
      "86        0.963855\n",
      "87        0.831892\n",
      "88        0.976710\n",
      "89        0.940484\n",
      "90        0.985182\n",
      "91        0.999944\n",
      "92        0.999888\n",
      "93        0.977797\n",
      "94        0.954286\n",
      "95        0.932584\n",
      "96        1.000000\n",
      "97        0.992366\n",
      "98        0.991863\n",
      "99        0.975888\n",
      "100       0.975298\n",
      "101       0.975554\n",
      "102       1.000000\n",
      "103       0.996226\n",
      "104       0.985126\n",
      "105       0.990741\n",
      "106       0.867700\n",
      "107       0.901583\n",
      "108       0.870856\n",
      "109       0.989602\n",
      "110       0.978571\n",
      "111       0.990741\n",
      "112       0.991789\n",
      "113       1.000000\n",
      "114       0.915686\n",
      "115       0.992481\n",
      "116       0.974966\n",
      "117       1.000000\n",
      "118       0.999832\n",
      "119       0.984615\n",
      "120       0.939024\n",
      "121       0.953647\n",
      "122       0.970588\n",
      "123       0.992801\n",
      "124       0.999944\n",
      "125       0.991071\n",
      "126       0.976183\n",
      "127       0.991094\n",
      "128       0.943503\n",
      "129       0.964029 \n",
      "\n",
      "Hidden layers:  216\n",
      "Score:  0.8798173312541768 Time:  180.17969846725464\n",
      "     Youdens Index\n",
      "0         0.999832\n",
      "1         0.990853\n",
      "2         0.944134\n",
      "3         0.746269\n",
      "4         0.928910\n",
      "5         0.956582\n",
      "6         0.944000\n",
      "7         0.873960\n",
      "8         0.924027\n",
      "9         0.966667\n",
      "10        0.975686\n",
      "11        0.939170\n",
      "12        0.946749\n",
      "13        0.548092\n",
      "14        0.971586\n",
      "15        0.999159\n",
      "16        0.906082\n",
      "17        0.966046\n",
      "18        0.937650\n",
      "19        0.697255\n",
      "20        0.990791\n",
      "21        0.884724\n",
      "22        0.983918\n",
      "23        0.985533\n",
      "24        0.960958\n",
      "25        0.973403\n",
      "26        1.000000\n",
      "27        0.933368\n",
      "28        0.922906\n",
      "29        1.000000\n",
      "30        0.999944\n",
      "31        0.941408\n",
      "32        0.947705\n",
      "33        0.928741\n",
      "34        0.793314\n",
      "35        0.908026\n",
      "36        0.949776\n",
      "37        0.906555\n",
      "38        0.976688\n",
      "39        0.951774\n",
      "40        0.969869\n",
      "41        0.993981\n",
      "42        0.984791\n",
      "43        0.968638\n",
      "44        0.991846\n",
      "45        0.921148\n",
      "46        0.956028\n",
      "47        0.991485\n",
      "48        0.991879\n",
      "49        0.934258\n",
      "50        0.918699\n",
      "51        0.999551\n",
      "52        0.869119\n",
      "53        0.974825\n",
      "54        0.999720\n",
      "55        0.819220\n",
      "56        0.943044\n",
      "57        0.899000\n",
      "58        0.728000\n",
      "59        0.833165\n",
      "60        0.798051\n",
      "61        0.880148\n",
      "62        0.213333\n",
      "63        0.753455\n",
      "64        0.992424\n",
      "65        0.999888\n",
      "66        0.951220\n",
      "67        0.981789\n",
      "68        0.918980\n",
      "69        0.954270\n",
      "70        0.927480\n",
      "71        0.870061\n",
      "72        0.978386\n",
      "73        0.878721\n",
      "74        0.820176\n",
      "75        0.896384\n",
      "76        0.999832\n",
      "77        0.959397\n",
      "78        0.944826\n",
      "79        0.864967\n",
      "80        0.907883\n",
      "81        0.956466\n",
      "82        0.857266\n",
      "83        0.874317\n",
      "84        0.938875\n",
      "85        0.944276\n",
      "86        0.915607\n",
      "87        0.729366\n",
      "88        0.975641\n",
      "89        0.934741\n",
      "90        0.969522\n",
      "91        0.973237\n",
      "92        0.966102\n",
      "93        0.796366\n",
      "94        0.948515\n",
      "95        0.959999\n",
      "96        0.730978\n",
      "97        0.991918\n",
      "98        0.799944\n",
      "99        0.982766\n",
      "100       0.926173\n",
      "101       0.926829\n",
      "102       0.999944\n",
      "103       0.969811\n",
      "104       0.933431\n",
      "105       0.996918\n",
      "106       0.706987\n",
      "107       0.852403\n",
      "108       0.885807\n",
      "109       0.857539\n",
      "110       0.913893\n",
      "111       0.907239\n",
      "112       0.912488\n",
      "113       0.946509\n",
      "114       0.865490\n",
      "115       0.992032\n",
      "116       0.924560\n",
      "117       0.999944\n",
      "118       0.812332\n",
      "119       0.989575\n",
      "120       0.980696\n",
      "121       0.916610\n",
      "122       0.999832\n",
      "123       0.950000\n",
      "124       0.960452\n",
      "125       0.928459\n",
      "126       0.713122\n",
      "127       0.946678\n",
      "128       0.999213\n",
      "129       0.905914 \n",
      "\n",
      "Hidden layers:  (216, 108)\n",
      "Score:  0.9103363778124304 Time:  138.0971188545227\n",
      "     Youdens Index\n",
      "0         0.954887\n",
      "1         0.972559\n",
      "2         0.953285\n",
      "3         0.894456\n",
      "4         0.976322\n",
      "5         0.985658\n",
      "6         0.999888\n",
      "7         0.944826\n",
      "8         0.939569\n",
      "9         0.966667\n",
      "10        0.936003\n",
      "11        0.969473\n",
      "12        0.973290\n",
      "13        0.960887\n",
      "14        0.990510\n",
      "15        0.999720\n",
      "16        0.963580\n",
      "17        0.931979\n",
      "18        0.910345\n",
      "19        0.946384\n",
      "20        0.999888\n",
      "21        0.942222\n",
      "22        0.849944\n",
      "23        0.992710\n",
      "24        0.987117\n",
      "25        0.999944\n",
      "26        1.000000\n",
      "27        0.876777\n",
      "28        0.795637\n",
      "29        1.000000\n",
      "30        0.999888\n",
      "31        0.952823\n",
      "32        0.895354\n",
      "33        0.929078\n",
      "34        0.856582\n",
      "35        0.826993\n",
      "36        0.932941\n",
      "37        0.965765\n",
      "38        0.968319\n",
      "39        0.979059\n",
      "40        0.992481\n",
      "41        0.994318\n",
      "42        0.999329\n",
      "43        0.929688\n",
      "44        0.987854\n",
      "45        0.991958\n",
      "46        0.946808\n",
      "47        0.899160\n",
      "48        0.975694\n",
      "49        0.966708\n",
      "50        0.999888\n",
      "51        0.999551\n",
      "52        0.984559\n",
      "53        0.902439\n",
      "54        0.967368\n",
      "55        0.860887\n",
      "56        0.916611\n",
      "57        0.837097\n",
      "58        0.959271\n",
      "59        0.903397\n",
      "60        0.975134\n",
      "61        0.932611\n",
      "62        0.873165\n",
      "63        0.796933\n",
      "64        0.924242\n",
      "65        0.971963\n",
      "66        0.963415\n",
      "67        0.981845\n",
      "68        0.914523\n",
      "69        0.992201\n",
      "70        0.999158\n",
      "71        0.960598\n",
      "72        0.930513\n",
      "73        0.762488\n",
      "74        0.854421\n",
      "75        0.939095\n",
      "76        0.974082\n",
      "77        0.983703\n",
      "78        0.952588\n",
      "79        0.944052\n",
      "80        0.988064\n",
      "81        0.991912\n",
      "82        0.964756\n",
      "83        0.983494\n",
      "84        0.992030\n",
      "85        0.838384\n",
      "86        0.927711\n",
      "87        0.809209\n",
      "88        0.970536\n",
      "89        0.940203\n",
      "90        0.992198\n",
      "91        0.881273\n",
      "92        0.974576\n",
      "93        0.944324\n",
      "94        0.988065\n",
      "95        0.948201\n",
      "96        0.985926\n",
      "97        0.992142\n",
      "98        0.873850\n",
      "99        0.991607\n",
      "100       0.950539\n",
      "101       0.975610\n",
      "102       0.999888\n",
      "103       0.995322\n",
      "104       0.816176\n",
      "105       0.981369\n",
      "106       0.828788\n",
      "107       0.901359\n",
      "108       0.806227\n",
      "109       0.708493\n",
      "110       0.970643\n",
      "111       0.989844\n",
      "112       0.960125\n",
      "113       1.000000\n",
      "114       0.907563\n",
      "115       0.977444\n",
      "116       0.875843\n",
      "117       0.999944\n",
      "118       0.867131\n",
      "119       0.994872\n",
      "120       0.969287\n",
      "121       0.985998\n",
      "122       0.992647\n",
      "123       0.957143\n",
      "124       0.988701\n",
      "125       0.982087\n",
      "126       0.782609\n",
      "127       0.972835\n",
      "128       0.881018\n",
      "129       0.812837 \n",
      "\n",
      "Hidden layers:  108\n",
      "Score:  0.7371352194252617 Time:  151.85168766975403\n",
      "     Youdens Index\n",
      "0         0.796712\n",
      "1         0.854489\n",
      "2         0.376530\n",
      "3         0.677365\n",
      "4         0.857090\n",
      "5         0.954729\n",
      "6         0.871720\n",
      "7         0.668843\n",
      "8         0.405510\n",
      "9         0.891330\n",
      "10        0.871165\n",
      "11        0.767397\n",
      "12        0.878159\n",
      "13        0.383895\n",
      "14        0.924528\n",
      "15        0.666218\n",
      "16        0.891525\n",
      "17        0.889326\n",
      "18        0.806840\n",
      "19        0.696806\n",
      "20        0.973214\n",
      "21        0.783331\n",
      "22        0.642576\n",
      "23        0.309671\n",
      "24        0.777413\n",
      "25        0.967239\n",
      "26        0.999944\n",
      "27        0.814490\n",
      "28        0.616165\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.940902\n",
      "32        0.693637\n",
      "33        0.769130\n",
      "34        0.657721\n",
      "35        0.826600\n",
      "36        0.923879\n",
      "37        0.830508\n",
      "38        0.898608\n",
      "39        0.951381\n",
      "40        0.932219\n",
      "41        0.970522\n",
      "42        0.749553\n",
      "43        0.819415\n",
      "44        0.999887\n",
      "45        0.582621\n",
      "46        0.972283\n",
      "47        0.982689\n",
      "48        0.959285\n",
      "49        0.884629\n",
      "50        0.541968\n",
      "51        0.990237\n",
      "52        0.599832\n",
      "53        0.934511\n",
      "54        0.731707\n",
      "55        0.638103\n",
      "56        0.674021\n",
      "57        0.932992\n",
      "58        0.798093\n",
      "59        0.665490\n",
      "60        0.217349\n",
      "61        0.036865\n",
      "62        0.658203\n",
      "63        0.686161\n",
      "64        0.870875\n",
      "65        0.999832\n",
      "66        0.841240\n",
      "67        0.894491\n",
      "68        0.719985\n",
      "69        0.976209\n",
      "70        0.593866\n",
      "71        0.740234\n",
      "72        0.877434\n",
      "73        0.745202\n",
      "74        0.768502\n",
      "75        0.843426\n",
      "76        0.887539\n",
      "77        0.917953\n",
      "78        0.676492\n",
      "79        0.689074\n",
      "80        0.912557\n",
      "81        0.933885\n",
      "82        0.655237\n",
      "83        0.935727\n",
      "84        0.923384\n",
      "85        0.843153\n",
      "86        0.867246\n",
      "87        0.743066\n",
      "88        0.709408\n",
      "89        0.754393\n",
      "90        0.712955\n",
      "91        0.731666\n",
      "92        0.948928\n",
      "93        0.669598\n",
      "94        0.862688\n",
      "95        0.796572\n",
      "96        0.779086\n",
      "97        0.946116\n",
      "98        0.703423\n",
      "99        0.783327\n",
      "100       0.958119\n",
      "101       0.894253\n",
      "102       0.978499\n",
      "103       0.983210\n",
      "104       0.742310\n",
      "105       0.804603\n",
      "106       0.479844\n",
      "107       0.735798\n",
      "108       0.626060\n",
      "109       0.456525\n",
      "110       0.876888\n",
      "111       0.916330\n",
      "112       0.786448\n",
      "113       0.999327\n",
      "114       0.914284\n",
      "115       0.879587\n",
      "116       0.827797\n",
      "117       0.968280\n",
      "118       0.764896\n",
      "119       0.943533\n",
      "120       0.876981\n",
      "121       0.758865\n",
      "122       0.985238\n",
      "123       0.763893\n",
      "124       0.852995\n",
      "125       0.937332\n",
      "126       0.601061\n",
      "127       0.964378\n",
      "128       0.935941\n",
      "129       0.754834 \n",
      "\n",
      "Hidden layers:  (108, 54)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8485186010247271 Time:  173.36493253707886\n",
      "     Youdens Index\n",
      "0         0.999439\n",
      "1         0.899496\n",
      "2         0.683998\n",
      "3         0.827629\n",
      "4         0.982625\n",
      "5         0.949775\n",
      "6         0.967383\n",
      "7         0.778630\n",
      "8         0.976995\n",
      "9         0.982997\n",
      "10        0.919625\n",
      "11        0.948935\n",
      "12        0.956994\n",
      "13        0.688159\n",
      "14        0.877358\n",
      "15        0.836985\n",
      "16        0.978081\n",
      "17        0.940566\n",
      "18        0.868629\n",
      "19        0.697311\n",
      "20        0.982087\n",
      "21        0.834027\n",
      "22        0.921092\n",
      "23        0.882702\n",
      "24        0.942195\n",
      "25        0.940867\n",
      "26        0.993056\n",
      "27        0.928234\n",
      "28        0.830507\n",
      "29        1.000000\n",
      "30        0.992366\n",
      "31        0.992690\n",
      "32        0.812760\n",
      "33        0.842071\n",
      "34        0.777329\n",
      "35        0.845174\n",
      "36        0.891667\n",
      "37        0.881356\n",
      "38        0.953320\n",
      "39        0.883393\n",
      "40        0.962182\n",
      "41        0.960002\n",
      "42        0.926247\n",
      "43        0.944920\n",
      "44        0.999944\n",
      "45        0.897077\n",
      "46        0.912225\n",
      "47        0.949468\n",
      "48        0.959621\n",
      "49        0.860319\n",
      "50        0.772021\n",
      "51        0.954607\n",
      "52        0.984111\n",
      "53        0.950659\n",
      "54        0.894253\n",
      "55        0.687219\n",
      "56        0.804827\n",
      "57        0.773960\n",
      "58        0.799832\n",
      "59        0.859089\n",
      "60        0.983422\n",
      "61        0.871451\n",
      "62        0.719214\n",
      "63        0.644198\n",
      "64        0.976880\n",
      "65        0.990598\n",
      "66        0.963135\n",
      "67        0.768034\n",
      "68        0.762132\n",
      "69        0.917125\n",
      "70        0.825357\n",
      "71        0.930400\n",
      "72        0.829506\n",
      "73        0.786958\n",
      "74        0.785708\n",
      "75        0.782857\n",
      "76        0.939655\n",
      "77        0.935428\n",
      "78        0.897077\n",
      "79        0.927674\n",
      "80        0.967061\n",
      "81        0.963431\n",
      "82        0.803380\n",
      "83        0.960229\n",
      "84        0.976538\n",
      "85        0.922947\n",
      "86        0.794957\n",
      "87        0.693094\n",
      "88        0.773723\n",
      "89        0.895665\n",
      "90        0.661540\n",
      "91        0.770868\n",
      "92        0.957627\n",
      "93        0.856749\n",
      "94        0.959719\n",
      "95        0.717695\n",
      "96        0.958565\n",
      "97        0.938707\n",
      "98        0.799102\n",
      "99        0.911720\n",
      "100       0.868292\n",
      "101       0.967199\n",
      "102       0.999888\n",
      "103       0.966038\n",
      "104       0.918725\n",
      "105       0.934625\n",
      "106       0.678405\n",
      "107       0.884573\n",
      "108       0.795303\n",
      "109       0.645108\n",
      "110       0.977954\n",
      "111       0.944276\n",
      "112       0.684591\n",
      "113       0.999832\n",
      "114       0.882129\n",
      "115       0.962238\n",
      "116       0.889287\n",
      "117       0.976322\n",
      "118       0.874159\n",
      "119       0.917611\n",
      "120       0.920170\n",
      "121       0.939533\n",
      "122       0.948529\n",
      "123       0.942464\n",
      "124       0.909548\n",
      "125       0.964118\n",
      "126       0.813673\n",
      "127       0.946622\n",
      "128       0.869157\n",
      "129       0.913388 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test/Configure runs\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Call process_files and assign variables\n",
    "X_grey_train, X_grey_validation, X_grey_test, Y_train, Y_validation, Y_test = process_files(data_path)\n",
    "\n",
    "print(\"Hidden layers configurations test\")\n",
    "for hl in [(432), (216), (216, 108), (108), (108, 54)]:\n",
    "    print(\"Hidden layers: \", hl)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hl, max_iter=500, random_state = 1)\n",
    "    t0 = time.time()\n",
    "    mlp.fit(X_grey_train, Y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"Score: \", mlp.score(X_grey_validation, Y_validation), \"Time: \", t1 - t0)\n",
    "    print(get_youdens_index(mlp.predict(X_grey_validation), Y_validation), \"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab86f6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Tests\n",
      "Alpha:  0.0001\n",
      "Score:  0.9411338828246826 Time:  189.20969986915588\n",
      "     Youdens Index\n",
      "0         0.999663\n",
      "1         0.981818\n",
      "2         0.915385\n",
      "3         0.932780\n",
      "4         0.991846\n",
      "5         0.999832\n",
      "6         0.991888\n",
      "7         0.999551\n",
      "8         0.984738\n",
      "9         0.998935\n",
      "10        0.983847\n",
      "11        0.989843\n",
      "12        0.998874\n",
      "13        0.955107\n",
      "14        0.952662\n",
      "15        0.968824\n",
      "16        0.956778\n",
      "17        0.966046\n",
      "18        0.930978\n",
      "19        0.731092\n",
      "20        0.973214\n",
      "21        0.956722\n",
      "22        0.985714\n",
      "23        0.999214\n",
      "24        0.987005\n",
      "25        0.999493\n",
      "26        1.000000\n",
      "27        0.980648\n",
      "28        0.958677\n",
      "29        1.000000\n",
      "30        0.992366\n",
      "31        0.988248\n",
      "32        0.962182\n",
      "33        0.991677\n",
      "34        0.856638\n",
      "35        0.881594\n",
      "36        0.966611\n",
      "37        0.940678\n",
      "38        0.992248\n",
      "39        0.965641\n",
      "40        0.977275\n",
      "41        1.000000\n",
      "42        0.941009\n",
      "43        0.991963\n",
      "44        0.999887\n",
      "45        0.991789\n",
      "46        0.894513\n",
      "47        1.000000\n",
      "48        0.975806\n",
      "49        0.999944\n",
      "50        0.837342\n",
      "51        0.999888\n",
      "52        0.999439\n",
      "53        0.926829\n",
      "54        0.983740\n",
      "55        0.944108\n",
      "56        0.952639\n",
      "57        0.960792\n",
      "58        0.959439\n",
      "59        0.990107\n",
      "60        0.990702\n",
      "61        0.992032\n",
      "62        0.813109\n",
      "63        0.948939\n",
      "64        0.999158\n",
      "65        0.990598\n",
      "66        0.999944\n",
      "67        0.834543\n",
      "68        0.980535\n",
      "69        0.962350\n",
      "70        0.999776\n",
      "71        0.984621\n",
      "72        0.914894\n",
      "73        0.898193\n",
      "74        0.940059\n",
      "75        0.982422\n",
      "76        0.999888\n",
      "77        0.951613\n",
      "78        0.984196\n",
      "79        0.991895\n",
      "80        0.994088\n",
      "81        0.992473\n",
      "82        0.938291\n",
      "83        0.950763\n",
      "84        0.946565\n",
      "85        0.979742\n",
      "86        0.903614\n",
      "87        0.824593\n",
      "88        0.930580\n",
      "89        0.988964\n",
      "90        0.860070\n",
      "91        0.968167\n",
      "92        0.999720\n",
      "93        0.934066\n",
      "94        0.999831\n",
      "95        0.988652\n",
      "96        0.972414\n",
      "97        0.999888\n",
      "98        0.888777\n",
      "99        0.928000\n",
      "100       0.942511\n",
      "101       0.991758\n",
      "102       0.999832\n",
      "103       0.950943\n",
      "104       0.955826\n",
      "105       0.990405\n",
      "106       0.886512\n",
      "107       0.934426\n",
      "108       0.870800\n",
      "109       0.944658\n",
      "110       0.985209\n",
      "111       0.972222\n",
      "112       0.929134\n",
      "113       1.000000\n",
      "114       0.907339\n",
      "115       0.999888\n",
      "116       0.950101\n",
      "117       1.000000\n",
      "118       0.968301\n",
      "119       0.974359\n",
      "120       0.993790\n",
      "121       0.990628\n",
      "122       0.999776\n",
      "123       0.992857\n",
      "124       0.999888\n",
      "125       0.910714\n",
      "126       0.930064\n",
      "127       1.000000\n",
      "128       0.932203\n",
      "129       0.992581 \n",
      "\n",
      "Alpha:  0.001\n",
      "Score:  0.9087213187792381 Time:  109.6138596534729\n",
      "     Youdens Index\n",
      "0         0.992201\n",
      "1         0.981650\n",
      "2         0.692308\n",
      "3         0.989395\n",
      "4         0.873847\n",
      "5         0.985602\n",
      "6         0.944000\n",
      "7         0.990668\n",
      "8         0.887218\n",
      "9         0.999495\n",
      "10        0.952381\n",
      "11        0.999832\n",
      "12        0.963102\n",
      "13        0.976263\n",
      "14        0.990566\n",
      "15        0.992136\n",
      "16        0.927665\n",
      "17        0.966102\n",
      "18        0.917185\n",
      "19        0.857087\n",
      "20        1.000000\n",
      "21        0.877642\n",
      "22        0.978403\n",
      "23        0.868909\n",
      "24        0.980619\n",
      "25        0.999662\n",
      "26        0.993056\n",
      "27        0.980986\n",
      "28        0.958846\n",
      "29        0.992188\n",
      "30        0.992366\n",
      "31        0.976271\n",
      "32        0.925317\n",
      "33        0.983859\n",
      "34        0.650738\n",
      "35        0.808867\n",
      "36        0.966555\n",
      "37        0.881300\n",
      "38        0.875913\n",
      "39        0.931338\n",
      "40        0.947256\n",
      "41        0.997919\n",
      "42        0.985238\n",
      "43        0.937444\n",
      "44        0.987798\n",
      "45        0.952756\n",
      "46        0.806849\n",
      "47        0.529412\n",
      "48        0.983254\n",
      "49        0.811475\n",
      "50        0.991477\n",
      "51        0.939794\n",
      "52        0.999439\n",
      "53        0.999495\n",
      "54        0.991758\n",
      "55        0.875000\n",
      "56        0.944276\n",
      "57        0.929896\n",
      "58        0.856000\n",
      "59        0.903229\n",
      "60        0.902721\n",
      "61        0.983952\n",
      "62        0.753165\n",
      "63        0.854848\n",
      "64        0.999215\n",
      "65        0.990598\n",
      "66        0.987525\n",
      "67        0.818182\n",
      "68        0.980479\n",
      "69        0.977388\n",
      "70        0.977587\n",
      "71        0.969185\n",
      "72        0.988855\n",
      "73        0.931699\n",
      "74        0.947933\n",
      "75        0.965461\n",
      "76        0.999832\n",
      "77        0.927307\n",
      "78        0.913330\n",
      "79        0.936340\n",
      "80        0.837725\n",
      "81        0.956466\n",
      "82        0.972131\n",
      "83        0.993860\n",
      "84        0.992310\n",
      "85        0.994837\n",
      "86        0.951751\n",
      "87        0.816957\n",
      "88        0.973392\n",
      "89        0.929223\n",
      "90        0.911765\n",
      "91        0.685039\n",
      "92        0.957627\n",
      "93        0.961257\n",
      "94        0.982801\n",
      "95        0.954831\n",
      "96        0.999158\n",
      "97        0.992142\n",
      "98        0.991807\n",
      "99        0.967607\n",
      "100       0.950539\n",
      "101       0.991533\n",
      "102       0.914894\n",
      "103       0.981132\n",
      "104       0.919118\n",
      "105       0.997535\n",
      "106       0.819970\n",
      "107       0.933809\n",
      "108       0.725526\n",
      "109       0.904783\n",
      "110       0.914286\n",
      "111       0.981425\n",
      "112       0.991453\n",
      "113       1.000000\n",
      "114       0.882185\n",
      "115       0.977388\n",
      "116       0.895927\n",
      "117       1.000000\n",
      "118       0.968582\n",
      "119       1.000000\n",
      "120       0.987580\n",
      "121       0.976626\n",
      "122       1.000000\n",
      "123       0.999551\n",
      "124       0.988251\n",
      "125       0.982143\n",
      "126       0.980794\n",
      "127       1.000000\n",
      "128       0.959946\n",
      "129       0.812894 \n",
      "\n",
      "Alpha:  0.01\n",
      "Score:  0.9367899309423035 Time:  138.42913222312927\n",
      "     Youdens Index\n",
      "0         0.999607\n",
      "1         0.954433\n",
      "2         0.899776\n",
      "3         0.969869\n",
      "4         0.944770\n",
      "5         0.999439\n",
      "6         0.999720\n",
      "7         0.976266\n",
      "8         0.999776\n",
      "9         0.999608\n",
      "10        0.976134\n",
      "11        0.999664\n",
      "12        0.978891\n",
      "13        0.903648\n",
      "14        0.990286\n",
      "15        0.968936\n",
      "16        0.913445\n",
      "17        0.949096\n",
      "18        0.889599\n",
      "19        0.965546\n",
      "20        0.999832\n",
      "21        0.934915\n",
      "22        0.999495\n",
      "23        0.923913\n",
      "24        0.993502\n",
      "25        0.989305\n",
      "26        1.000000\n",
      "27        0.999493\n",
      "28        0.964004\n",
      "29        0.999944\n",
      "30        0.992366\n",
      "31        0.982400\n",
      "32        0.984121\n",
      "33        0.913218\n",
      "34        0.817292\n",
      "35        0.936027\n",
      "36        0.916667\n",
      "37        0.966102\n",
      "38        0.968992\n",
      "39        0.958511\n",
      "40        0.947368\n",
      "41        0.999831\n",
      "42        0.925967\n",
      "43        0.984207\n",
      "44        0.995782\n",
      "45        0.952588\n",
      "46        0.991172\n",
      "47        1.000000\n",
      "48        0.846774\n",
      "49        0.950764\n",
      "50        0.966751\n",
      "51        0.999495\n",
      "52        0.969119\n",
      "53        0.951220\n",
      "54        0.975554\n",
      "55        0.923274\n",
      "56        0.879293\n",
      "57        0.961016\n",
      "58        0.775944\n",
      "59        0.938036\n",
      "60        0.903114\n",
      "61        0.940130\n",
      "62        0.713221\n",
      "63        0.905236\n",
      "64        0.962009\n",
      "65        1.000000\n",
      "66        0.938857\n",
      "67        0.983191\n",
      "68        0.971508\n",
      "69        0.977444\n",
      "70        0.963600\n",
      "71        0.900707\n",
      "72        0.936114\n",
      "73        0.898193\n",
      "74        0.956929\n",
      "75        0.973970\n",
      "76        0.999496\n",
      "77        0.895161\n",
      "78        0.937008\n",
      "79        0.990942\n",
      "80        0.999550\n",
      "81        0.985339\n",
      "82        0.931534\n",
      "83        0.972453\n",
      "84        0.984733\n",
      "85        0.979629\n",
      "86        0.927599\n",
      "87        0.896744\n",
      "88        0.965318\n",
      "89        0.993751\n",
      "90        0.985294\n",
      "91        0.968392\n",
      "92        0.982939\n",
      "93        0.955988\n",
      "94        0.971316\n",
      "95        0.971854\n",
      "96        0.986207\n",
      "97        0.954142\n",
      "98        0.918182\n",
      "99        0.920000\n",
      "100       0.926117\n",
      "101       0.967480\n",
      "102       0.999944\n",
      "103       0.999548\n",
      "104       0.940952\n",
      "105       0.990461\n",
      "106       0.913694\n",
      "107       0.967101\n",
      "108       0.942988\n",
      "109       0.944489\n",
      "110       0.978347\n",
      "111       0.981425\n",
      "112       0.944882\n",
      "113       0.999888\n",
      "114       0.949300\n",
      "115       1.000000\n",
      "116       0.925630\n",
      "117       0.992126\n",
      "118       0.984038\n",
      "119       0.938405\n",
      "120       0.877936\n",
      "121       0.902778\n",
      "122       0.999832\n",
      "123       0.971429\n",
      "124       0.999775\n",
      "125       0.990623\n",
      "126       0.906079\n",
      "127       0.964602\n",
      "128       0.966102\n",
      "129       0.949640 \n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.9357317888171085 Time:  182.7343099117279\n",
      "     Youdens Index\n",
      "0         0.999832\n",
      "1         0.999888\n",
      "2         0.845817\n",
      "3         0.716362\n",
      "4         0.944770\n",
      "5         0.992689\n",
      "6         1.000000\n",
      "7         0.952756\n",
      "8         0.924812\n",
      "9         0.999944\n",
      "10        0.960205\n",
      "11        0.969473\n",
      "12        0.994681\n",
      "13        0.925701\n",
      "14        0.971698\n",
      "15        0.976464\n",
      "16        0.942109\n",
      "17        0.948984\n",
      "18        0.862069\n",
      "19        0.714286\n",
      "20        0.991071\n",
      "21        0.949584\n",
      "22        0.864286\n",
      "23        0.990914\n",
      "24        0.949199\n",
      "25        0.988911\n",
      "26        1.000000\n",
      "27        0.985613\n",
      "28        0.968599\n",
      "29        1.000000\n",
      "30        0.977099\n",
      "31        0.999888\n",
      "32        0.955112\n",
      "33        0.842464\n",
      "34        0.872455\n",
      "35        0.954321\n",
      "36        0.966555\n",
      "37        0.923673\n",
      "38        0.930120\n",
      "39        0.999944\n",
      "40        0.999832\n",
      "41        0.999888\n",
      "42        0.941121\n",
      "43        0.976226\n",
      "44        0.943320\n",
      "45        0.952700\n",
      "46        0.999496\n",
      "47        0.999832\n",
      "48        0.967742\n",
      "49        0.745902\n",
      "50        0.991197\n",
      "51        0.999719\n",
      "52        0.984447\n",
      "53        0.999944\n",
      "54        0.991870\n",
      "55        0.985718\n",
      "56        0.943716\n",
      "57        0.976408\n",
      "58        0.943888\n",
      "59        0.991004\n",
      "60        0.661290\n",
      "61        0.888060\n",
      "62        0.925937\n",
      "63        0.984778\n",
      "64        1.000000\n",
      "65        0.999944\n",
      "66        0.999888\n",
      "67        0.998935\n",
      "68        0.995092\n",
      "69        0.969925\n",
      "70        0.941917\n",
      "71        0.938763\n",
      "72        0.936170\n",
      "73        0.915086\n",
      "74        0.965588\n",
      "75        0.947883\n",
      "76        0.974138\n",
      "77        0.919355\n",
      "78        0.976322\n",
      "79        0.976134\n",
      "80        0.999775\n",
      "81        0.963768\n",
      "82        0.912050\n",
      "83        0.950820\n",
      "84        0.991693\n",
      "85        0.979685\n",
      "86        0.951751\n",
      "87        0.882875\n",
      "88        0.988383\n",
      "89        0.918694\n",
      "90        0.999383\n",
      "91        0.952644\n",
      "92        0.966102\n",
      "93        0.961426\n",
      "94        0.999775\n",
      "95        0.999606\n",
      "96        0.992823\n",
      "97        0.992310\n",
      "98        0.970090\n",
      "99        0.879944\n",
      "100       0.950595\n",
      "101       0.796748\n",
      "102       0.999944\n",
      "103       0.996170\n",
      "104       0.948417\n",
      "105       0.981481\n",
      "106       0.858154\n",
      "107       0.917472\n",
      "108       0.766073\n",
      "109       0.881553\n",
      "110       0.985602\n",
      "111       0.972222\n",
      "112       0.905512\n",
      "113       0.999327\n",
      "114       0.941120\n",
      "115       0.962350\n",
      "116       0.969959\n",
      "117       0.991902\n",
      "118       0.999776\n",
      "119       1.000000\n",
      "120       0.963134\n",
      "121       0.939815\n",
      "122       0.999663\n",
      "123       0.999944\n",
      "124       0.949153\n",
      "125       1.000000\n",
      "126       0.697562\n",
      "127       0.964490\n",
      "128       0.988588\n",
      "129       0.956442 \n",
      "\n",
      "Alpha:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.9547226553798174 Time:  141.35582828521729\n",
      "     Youdens Index\n",
      "0         0.999776\n",
      "1         0.772727\n",
      "2         0.961538\n",
      "3         0.970093\n",
      "4         0.992126\n",
      "5         1.000000\n",
      "6         0.999832\n",
      "7         0.992070\n",
      "8         0.984962\n",
      "9         0.999888\n",
      "10        0.984071\n",
      "11        0.999944\n",
      "12        0.999775\n",
      "13        0.999663\n",
      "14        1.000000\n",
      "15        0.992136\n",
      "16        0.962906\n",
      "17        0.940566\n",
      "18        0.923913\n",
      "19        0.823529\n",
      "20        1.000000\n",
      "21        0.985331\n",
      "22        1.000000\n",
      "23        0.986207\n",
      "24        0.987342\n",
      "25        0.999944\n",
      "26        1.000000\n",
      "27        0.976303\n",
      "28        0.953969\n",
      "29        1.000000\n",
      "30        0.999607\n",
      "31        0.999269\n",
      "32        0.932724\n",
      "33        0.992014\n",
      "34        0.746032\n",
      "35        0.917734\n",
      "36        0.899944\n",
      "37        0.923729\n",
      "38        1.000000\n",
      "39        0.945149\n",
      "40        0.969925\n",
      "41        0.943182\n",
      "42        0.955882\n",
      "43        0.999888\n",
      "44        0.983806\n",
      "45        0.952756\n",
      "46        1.000000\n",
      "47        0.999944\n",
      "48        0.975750\n",
      "49        0.983607\n",
      "50        0.804878\n",
      "51        0.999776\n",
      "52        0.999944\n",
      "53        0.999776\n",
      "54        1.000000\n",
      "55        0.986111\n",
      "56        0.935129\n",
      "57        0.937760\n",
      "58        0.999776\n",
      "59        0.982232\n",
      "60        0.999720\n",
      "61        0.999719\n",
      "62        0.973333\n",
      "63        0.963768\n",
      "64        1.000000\n",
      "65        0.990598\n",
      "66        0.975554\n",
      "67        0.958678\n",
      "68        0.962029\n",
      "69        0.977444\n",
      "70        0.818841\n",
      "71        0.916031\n",
      "72        0.993724\n",
      "73        0.940454\n",
      "74        0.939891\n",
      "75        0.956897\n",
      "76        1.000000\n",
      "77        0.983871\n",
      "78        0.992070\n",
      "79        0.991839\n",
      "80        0.994595\n",
      "81        0.992698\n",
      "82        0.972917\n",
      "83        0.983325\n",
      "84        0.984508\n",
      "85        0.984792\n",
      "86        0.891566\n",
      "87        0.926727\n",
      "88        0.988158\n",
      "89        0.972917\n",
      "90        0.955882\n",
      "91        0.937008\n",
      "92        0.915254\n",
      "93        0.977347\n",
      "94        0.988346\n",
      "95        0.910056\n",
      "96        1.000000\n",
      "97        0.999944\n",
      "98        0.948148\n",
      "99        0.991944\n",
      "100       0.967045\n",
      "101       0.975610\n",
      "102       1.000000\n",
      "103       0.950943\n",
      "104       0.999607\n",
      "105       0.999944\n",
      "106       0.961648\n",
      "107       0.942399\n",
      "108       0.950547\n",
      "109       0.928236\n",
      "110       0.985546\n",
      "111       0.971998\n",
      "112       0.968392\n",
      "113       0.992366\n",
      "114       0.915966\n",
      "115       0.947368\n",
      "116       0.979916\n",
      "117       0.992070\n",
      "118       0.953013\n",
      "119       0.964103\n",
      "120       0.957092\n",
      "121       0.967593\n",
      "122       1.000000\n",
      "123       0.985602\n",
      "124       0.994350\n",
      "125       0.999944\n",
      "126       0.991294\n",
      "127       0.973451\n",
      "128       0.999494\n",
      "129       0.978137 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default alpha=0.0001\n",
    "# HL (216, 108) appears perform the best, use that for alpha tests\n",
    "print(\"Alpha Tests\")\n",
    "for a in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "    print(\"Alpha: \", a)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(216, 108), alpha=a, max_iter=500, random_state = 1)\n",
    "    t0 = time.time()\n",
    "    mlp.fit(X_grey_train, Y_train)\n",
    "    t1 = time.time()\n",
    "    print(\"Score: \", mlp.score(X_grey_validation, Y_validation), \"Time: \", t1 - t0)\n",
    "    print(get_youdens_index(mlp.predict(X_grey_validation), Y_validation), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637e1b91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning to fit model ... \n",
      "\n",
      "Grey model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       101\n",
      "           1       1.00      1.00      1.00       110\n",
      "           2       0.92      0.93      0.93       113\n",
      "           3       0.98      0.99      0.99       131\n",
      "           4       0.89      0.90      0.90        93\n",
      "           5       1.00      0.90      0.95        99\n",
      "           6       0.97      1.00      0.98        98\n",
      "           7       1.00      0.92      0.96       117\n",
      "           8       1.00      0.66      0.79       105\n",
      "           9       0.96      0.99      0.97        94\n",
      "          10       0.81      1.00      0.89        88\n",
      "          11       0.98      1.00      0.99       133\n",
      "          12       0.90      1.00      0.95       131\n",
      "          13       0.93      0.95      0.94       114\n",
      "          14       1.00      0.94      0.97        88\n",
      "          15       0.83      1.00      0.90       100\n",
      "          16       0.99      0.85      0.91        98\n",
      "          17       1.00      0.74      0.85        97\n",
      "          18       0.94      0.95      0.94       107\n",
      "          19       0.85      0.94      0.89        93\n",
      "          20       1.00      1.00      1.00        96\n",
      "          21       0.46      0.98      0.63       115\n",
      "          22       1.00      0.89      0.94       108\n",
      "          23       0.72      1.00      0.84        94\n",
      "          24       1.00      0.68      0.81       108\n",
      "          25       0.90      0.99      0.95       151\n",
      "          26       1.00      1.00      1.00       102\n",
      "          27       0.94      0.98      0.96       131\n",
      "          28       0.99      0.96      0.98       149\n",
      "          29       1.00      1.00      1.00       116\n",
      "          30       1.00      1.00      1.00       109\n",
      "          31       1.00      0.69      0.82        94\n",
      "          32       1.00      0.81      0.89        98\n",
      "          33       0.99      0.95      0.97       119\n",
      "          34       1.00      0.60      0.75       109\n",
      "          35       0.86      0.98      0.92        95\n",
      "          36       0.82      0.98      0.89       100\n",
      "          37       0.97      0.97      0.97        64\n",
      "          38       0.96      1.00      0.98       116\n",
      "          39       1.00      0.97      0.99       107\n",
      "          40       0.99      0.98      0.98        96\n",
      "          41       0.94      1.00      0.97       154\n",
      "          42       0.89      0.94      0.92        70\n",
      "          43       0.89      0.98      0.93       101\n",
      "          44       1.00      1.00      1.00       208\n",
      "          45       1.00      0.89      0.94       108\n",
      "          46       0.99      0.97      0.98       102\n",
      "          47       0.98      1.00      0.99       119\n",
      "          48       1.00      1.00      1.00       105\n",
      "          49       1.00      0.85      0.92       113\n",
      "          50       1.00      0.70      0.82       112\n",
      "          51       0.97      1.00      0.99       116\n",
      "          52       1.00      0.97      0.98        98\n",
      "          53       0.97      0.98      0.98       109\n",
      "          54       1.00      0.95      0.97       110\n",
      "          55       0.99      0.87      0.93        94\n",
      "          56       0.97      0.91      0.94       114\n",
      "          57       0.98      0.92      0.95       105\n",
      "          58       0.98      0.95      0.96        99\n",
      "          59       0.95      0.62      0.75        92\n",
      "          60       1.00      0.76      0.87       102\n",
      "          61       0.99      0.87      0.92        98\n",
      "          62       0.84      0.94      0.89        99\n",
      "          63       0.45      1.00      0.62       102\n",
      "          64       1.00      0.87      0.93       100\n",
      "          65       0.99      1.00      1.00       100\n",
      "          66       0.97      0.98      0.98        65\n",
      "          67       0.97      0.89      0.93       105\n",
      "          68       1.00      0.95      0.98       152\n",
      "          69       0.96      0.99      0.98       107\n",
      "          70       1.00      0.57      0.73       109\n",
      "          71       0.97      0.99      0.98        95\n",
      "          72       1.00      0.84      0.92       135\n",
      "          73       0.91      0.94      0.93       123\n",
      "          74       1.00      0.82      0.90        79\n",
      "          75       0.56      0.99      0.71        96\n",
      "          76       0.99      0.99      0.99       106\n",
      "          77       0.99      0.94      0.97       104\n",
      "          78       0.97      0.97      0.97        96\n",
      "          79       1.00      0.67      0.80       100\n",
      "          80       0.98      1.00      0.99       163\n",
      "          81       0.86      1.00      0.92       116\n",
      "          82       1.00      0.73      0.84       118\n",
      "          83       0.89      0.98      0.93       156\n",
      "          84       0.94      1.00      0.97        95\n",
      "          85       0.99      0.99      0.99       159\n",
      "          86       1.00      0.99      0.99        69\n",
      "          87       0.54      0.96      0.69       110\n",
      "          88       0.94      0.93      0.93       143\n",
      "          89       0.99      0.74      0.85       145\n",
      "          90       0.90      0.99      0.95        96\n",
      "          91       0.94      1.00      0.97       107\n",
      "          92       1.00      0.99      0.99        88\n",
      "          93       0.87      1.00      0.93       160\n",
      "          94       1.00      0.97      0.99       141\n",
      "          95       0.98      0.94      0.96       153\n",
      "          96       1.00      0.91      0.95        95\n",
      "          97       0.92      0.94      0.93       123\n",
      "          98       0.99      0.84      0.91       101\n",
      "          99       0.89      1.00      0.94       109\n",
      "         100       0.93      0.99      0.96        97\n",
      "         101       1.00      0.97      0.99        78\n",
      "         102       0.98      1.00      0.99        84\n",
      "         103       1.00      0.97      0.99       197\n",
      "         104       0.99      0.80      0.88        90\n",
      "         105       0.99      0.91      0.95        90\n",
      "         106       0.60      1.00      0.75        80\n",
      "         107       0.94      0.97      0.95        90\n",
      "         108       0.97      0.82      0.89       104\n",
      "         109       1.00      0.54      0.70        93\n",
      "         110       0.96      0.94      0.95       118\n",
      "         111       0.96      0.99      0.98       129\n",
      "         112       0.98      0.97      0.97       124\n",
      "         113       1.00      0.98      0.99       105\n",
      "         114       1.00      0.93      0.97       105\n",
      "         115       1.00      1.00      1.00        98\n",
      "         116       0.95      0.86      0.90       156\n",
      "         117       1.00      0.92      0.96        88\n",
      "         118       0.93      0.99      0.96       120\n",
      "         119       1.00      0.94      0.97       140\n",
      "         120       1.00      0.96      0.98       163\n",
      "         121       0.97      0.98      0.98       146\n",
      "         122       1.00      0.97      0.98        98\n",
      "         123       1.00      0.99      0.99        92\n",
      "         124       0.99      1.00      0.99       147\n",
      "         125       0.98      0.89      0.93        71\n",
      "         126       0.91      0.93      0.92        85\n",
      "         127       0.99      0.98      0.99       101\n",
      "         128       0.98      0.95      0.96       141\n",
      "         129       0.99      0.95      0.97        99\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     14365\n",
      "   macro avg       0.95      0.93      0.93     14365\n",
      "weighted avg       0.95      0.93      0.93     14365\n",
      " samples avg       0.90      0.93      0.91     14365\n",
      "\n",
      "     Youdens Index\n",
      "0         0.998528\n",
      "1         1.000000\n",
      "2         0.928572\n",
      "3         0.992226\n",
      "4         0.902525\n",
      "5         0.898990\n",
      "6         0.999790\n",
      "7         0.923077\n",
      "8         0.657143\n",
      "9         0.989081\n",
      "10        0.998529\n",
      "11        0.999789\n",
      "12        0.998946\n",
      "13        0.946807\n",
      "14        0.943182\n",
      "15        0.998528\n",
      "16        0.846869\n",
      "17        0.742268\n",
      "18        0.952780\n",
      "19        0.934433\n",
      "20        1.000000\n",
      "21        0.973416\n",
      "22        0.888889\n",
      "23        0.997477\n",
      "24        0.675926\n",
      "25        0.992252\n",
      "26        1.000000\n",
      "27        0.984171\n",
      "28        0.959661\n",
      "29        1.000000\n",
      "30        1.000000\n",
      "31        0.691489\n",
      "32        0.806122\n",
      "33        0.949510\n",
      "34        0.596330\n",
      "35        0.977896\n",
      "36        0.978458\n",
      "37        0.968610\n",
      "38        0.999649\n",
      "39        0.971963\n",
      "40        0.979097\n",
      "41        0.999367\n",
      "42        0.942298\n",
      "43        0.979357\n",
      "44        0.999929\n",
      "45        0.888889\n",
      "46        0.970518\n",
      "47        0.999789\n",
      "48        1.000000\n",
      "49        0.849558\n",
      "50        0.696429\n",
      "51        0.999789\n",
      "52        0.969388\n",
      "53        0.981441\n",
      "54        0.945455\n",
      "55        0.872270\n",
      "56        0.912070\n",
      "57        0.923669\n",
      "58        0.949355\n",
      "59        0.619355\n",
      "60        0.764706\n",
      "61        0.867277\n",
      "62        0.938132\n",
      "63        0.991306\n",
      "64        0.870000\n",
      "65        0.999930\n",
      "66        0.984476\n",
      "67        0.885504\n",
      "68        0.953947\n",
      "69        0.990374\n",
      "70        0.568807\n",
      "71        0.989263\n",
      "72        0.844444\n",
      "73        0.942317\n",
      "74        0.822785\n",
      "75        0.984327\n",
      "76        0.990496\n",
      "77        0.942238\n",
      "78        0.968540\n",
      "79        0.670000\n",
      "80        0.999789\n",
      "81        0.998667\n",
      "82        0.728814\n",
      "83        0.979432\n",
      "84        0.999580\n",
      "85        0.993570\n",
      "86        0.985507\n",
      "87        0.957253\n",
      "88        0.929437\n",
      "89        0.737861\n",
      "90        0.988883\n",
      "91        0.999509\n",
      "92        0.988636\n",
      "93        0.998381\n",
      "94        0.971631\n",
      "95        0.940965\n",
      "96        0.905263\n",
      "97        0.942387\n",
      "98        0.841514\n",
      "99        0.999088\n",
      "100       0.989200\n",
      "101       0.974359\n",
      "102       0.999860\n",
      "103       0.974619\n",
      "104       0.799930\n",
      "105       0.911041\n",
      "106       0.996290\n",
      "107       0.966246\n",
      "108       0.817097\n",
      "109       0.537634\n",
      "110       0.940327\n",
      "111       0.991897\n",
      "112       0.967531\n",
      "113       0.980952\n",
      "114       0.933333\n",
      "115       1.000000\n",
      "116       0.858482\n",
      "117       0.920455\n",
      "118       0.991035\n",
      "119       0.935714\n",
      "120       0.957055\n",
      "121       0.979171\n",
      "122       0.969388\n",
      "123       0.989130\n",
      "124       0.999859\n",
      "125       0.887254\n",
      "126       0.928852\n",
      "127       0.980128\n",
      "128       0.950144\n",
      "129       0.949425 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HL (216, 108) and alpha=1 seems to be the best based on results above.\n",
    "# Train the model with this and let's finally see how it performs on test.\n",
    "print('Beginning to fit model ... \\n')\n",
    "mlpc_grey =  MLPClassifier(hidden_layer_sizes=(216, 108), alpha=1, activation='relu', solver='adam', random_state=1, max_iter=500)\n",
    "mlpc_grey.fit(X_grey_train, Y_train)\n",
    "grey_test_result = mlpc_grey.predict(X_grey_test)\n",
    "\n",
    "print(\"Grey model\")\n",
    "print(classification_report(Y_test, grey_test_result, zero_division=0))\n",
    "print(get_youdens_index(grey_test_result, Y_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1eb45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
